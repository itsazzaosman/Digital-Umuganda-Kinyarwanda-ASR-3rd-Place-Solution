{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaafc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7314f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact -p GPU-shared --gres=gpu:v100-32:1 -t 1:00:00\n",
    "# conda activate /ocean/projects/cis250085p/shared/envPreproces\n",
    "# jupyter notebook --no-browser --ip=0.0.0.0\n",
    "\n",
    "# module load  AI/pytorch_23.02-1.13.1-py3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module avail AI/pytorch_23.02-1.13.1-py3\n",
    "\n",
    "# srun --jobid=32754720 --pty bash\n",
    "\n",
    "# # !module load ffmpeg/4.3.1\n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "# os.environ[\"PATH\"] += os.pathsep + \"/opt/packages/ffmpeg/4.3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = '/shared/B_track/processed/audio'\n",
    "raw_data = '/shared/A_track/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "processed_data = '/shared/B_track/audio'\n",
    "raw_data = '/shared/track_b_audio_files'\n",
    "\n",
    "processed_files = os.listdir(processed_data)\n",
    "processed_files = [f[:-7] for f in processed_files]\n",
    "raw_files = os.listdir(raw_data)\n",
    "print(f\"Number of raw files: {len(raw_files)}\")\n",
    "print(f\"Number of processed files: {len(processed_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_files = set(processed_files)\n",
    "files_to_process = [f for f in raw_files if f not in processed_files]\n",
    "print(f\"Number of files to process: {len(files_to_process)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1db9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# audio_path = \"/shared/A_track/1736843853-lWPStQITn7XCnMqYWAPbr3y3blg1\"\n",
    "\n",
    "# processed_path = \"/shared/A_track/processed/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aad578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_json_path = \"/shared/B_track/train.json\"\n",
    "train_df = pd.read_json(train_json_path).T\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48678edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70987a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np\n",
    "# from datasets import Dataset\n",
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "raw_path = \"/shared/A_track/\"\n",
    "\n",
    "\n",
    "def load_audio_and_compute_mel(example, target_sr=16000):\n",
    "    path = example\n",
    "    waveform, sr = torchaudio.load(raw_path + path)\n",
    "    if sr != target_sr:\n",
    "        waveform = torchaudio.functional.resample(waveform, sr, target_sr,)\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)  # mono\n",
    "    mel = feature_extractor(waveform.squeeze(), sampling_rate=target_sr\n",
    "    , device=\"cuda\"\n",
    "    ).input_features[0]\n",
    "    torch.save(mel, raw_path + \"processed/{}.mel.pt\".format(example))\n",
    "    # return mel\n",
    "\n",
    "for i in range(len(files_to_process)):\n",
    "    load_audio_and_compute_mel(\"audio/\" +files_to_process[i])\n",
    "    if i % 100 ==0:\n",
    "        print(i +1 , \"/\", len(files_to_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a52f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "num_cpu_cores = os.cpu_count()\n",
    "print(f\"Number of CPU cores: {num_cpu_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792395b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9eb03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !module load ffmpeg/4.3.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc9412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363563c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_json_path = \"/shared/A_track/train.json\"\n",
    "train_df = pd.read_json(train_json_path).T\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e697e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb4f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7b9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "audio_file = \"output.wav\"\n",
    "ipd.Audio(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67053a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# First, install the Kaggle API if not already installed\n",
    "# !pip install kaggle\n",
    "\n",
    "# Set up Kaggle API credentials (upload your kaggle.json or set environment variables)\n",
    "# from google.colab import files\n",
    "# files.upload()  # Upload kaggle.json\n",
    "\n",
    "\n",
    "# os.environ['KAGGLE_USERNAME'] = 'your_kaggle_username'\n",
    "# os.environ['KAGGLE_KEY'] = 'your_kaggle_key'\n",
    "\n",
    "\n",
    "# Zip the processed directory\n",
    "shutil.make_archive('/A_track/processed', 'zip', '/A_track/processed')\n",
    "\n",
    "# Create a dataset metadata file\n",
    "dataset_metadata = {\n",
    "    \"title\": \"A Track Processed Audio\",\n",
    "    \"id\": \"your-kaggle-username/a-track-processed-audio\",\n",
    "    \"licenses\": [{\"name\": \"CC0-1.0\"}],\n",
    "    \"private\": True\n",
    "}\n",
    "\n",
    "with open('/A_track/processed/dataset-metadata.json', 'w') as f:\n",
    "    json.dump(dataset_metadata, f, indent=4)\n",
    "\n",
    "# Use Kaggle API to create the dataset\n",
    "# !kaggle datasets create -p /shared/A_track/processed --dir-mode zip\n",
    "\n",
    "# Note: Replace 'your-kaggle-username' with your actual Kaggle username.\n",
    "# The dataset will be private by default due to \"private\": True in metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bccc35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset metadata file\n",
    "dataset_metadata = {\n",
    "    \"title\": \"A Track Processed Audio\",\n",
    "    \"id\": \"mansourhassan/a-track-processed-audio\",\n",
    "    \"licenses\": [{\"name\": \"CC0-1.0\"}],\n",
    "    \"private\": True\n",
    "}\n",
    "\n",
    "with open('/A_track/processed/dataset-metadata.json', 'w') as f:\n",
    "    json.dump(dataset_metadata, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = 'key'\n",
    "os.environ['KAGGLE_KEY'] = \"key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81953f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!kaggle datasets create -p shared/A_track -q --dir-mode tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ceba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets init -p /shared/A_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72337351",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nano /shared/A_track/processed/dataset-metadata.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcba3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -0 -r processed_track_a.zip /shared/A_track/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -0 -r -P 16 processed_track_a_5_process.zip /shared/A_track/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1260bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def sum_range(start, end):\n",
    "    return sum(range(start, end))\n",
    "\n",
    "def sum_serial():\n",
    "    start_time = time.time()\n",
    "    total = sum(range(0, 100001))\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Serial sum: {total}, Time: {elapsed:.4f} seconds\")\n",
    "    return elapsed\n",
    "\n",
    "def sum_parallel(num_workers=15):\n",
    "    chunk_size = 100001 // num_workers\n",
    "    ranges = [(i * chunk_size, (i + 1) * chunk_size) for i in range(num_workers)]\n",
    "    ranges[-1] = (ranges[-1][0], 100001)  # Ensure last chunk goes to 100000\n",
    "\n",
    "    start_time = time.time()\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(executor.map(lambda args: sum_range(*args), ranges))\n",
    "    total = sum(results)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Parallel sum: {total}, Time: {elapsed:.4f} seconds\")\n",
    "    return elapsed\n",
    "\n",
    "serial_time = sum_serial()\n",
    "parallel_time = sum_parallel()\n",
    "print(f\"Speedup: {serial_time/parallel_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd414a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
