{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "import os\n",
    "\n",
    "os.environ[\"NEMO_CACHE_DIR\"] = \"/A_track/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "pretrained_name=\"nvidia/canary-1b\" # or \"nvidia/parakeet-ctc-1.1b\"\n",
    "\n",
    "model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(pretrained_name, refresh_cache = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c69e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasample = \"/track_a_audio_files/1736843853-lWPStQITn7XCnMqYWAPbr3y3blg1.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec86f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transcribe([datasample])[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e23c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "print(OmegaConf.to_yaml(model.cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def standardize_quotation(train_df):\n",
    "    replacements = {\n",
    "        \"’\": \"'\",\n",
    "        \"‘\": \"'\",\n",
    "        \"“\": '\"',\n",
    "        \"”\": '\"',\n",
    "        \"\\n\": '',\n",
    "        u'\\xa0': u' ',\n",
    "\n",
    "        '，':',',\n",
    "\n",
    "        '&': \"uye\",\n",
    "        '<': \"\",\n",
    "        '*': \"\",\n",
    "        '>': \"\",\n",
    "        '#': \"\",\n",
    "        '…': \".\",\n",
    "        '．': \".\",\n",
    "        '+': \"\",\n",
    "        '=': \"\",\n",
    "        '≠':'',\n",
    "        '[': \"(\",\n",
    "        ']': \")\",\n",
    "        '_':'-',\n",
    "\n",
    "        'é': 'e',\n",
    "        'ü': 'u',\n",
    "        'ì': 'i',\n",
    "        'ķ': 'k',\n",
    "        'è': 'e',\n",
    "    }\n",
    "    pattern = re.compile(\"|\".join(map(re.escape, replacements.keys())))\n",
    "    train_df[\"transcription\"] = train_df[\"transcription\"].str.replace(\n",
    "        pattern, lambda m: replacements[m.group()], regex=True\n",
    "    )\n",
    "    return train_df[[\"transcription\"]]\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"transcription\"] = standardize_quotation(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d494d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./scripts/tokenizers/process_asr_text_tokenizer.py\"):\n",
    "  !mkdir scripts\n",
    "  !wget -P scripts/ \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/tokenizers/process_asr_text_tokenizer.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"shared/A_track/\"\n",
    "train_json_path = \"shared/A_track/train.json\"\n",
    "dev_json_path = \"shared/A_track/dev_test.json\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_df = pd.read_json(train_json_path).T\n",
    "\n",
    "# dev_df = pd.read_json(dev_json_path).T\n",
    "\n",
    "\n",
    "\n",
    "train_df[\"file_path\"] = \"processed/\"+ train_df[\"audio_path\"] +\".mel.pt\"\n",
    "dev_df[\"file_path\"] = \"processed/\"+ dev_df[\"audio_path\"] +\".mel.pt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a91b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "train_df[train_df[\"transcription\"].str.contains(r'\\d')][[\"transcription\", 'voice_creator_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe89205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"transcription\"].str.contains(r\"’\")][[\"transcription\", 'voice_creator_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"transcription\"].str.contains(r'\"')][[\"transcription\", 'voice_creator_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1787d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"transcription\"].str.contains(r'/')][[\"transcription\", 'voice_creator_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62126af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84faeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern_with_space_dot = r\"[^a-zA-Z0-9()'\\\" .,’\\-:;]\"\n",
    "train_df[train_df[\"transcription\"].str.contains(pattern_with_space_dot)][[\"transcription\", 'voice_creator_id']]\n",
    "def find_non_matching(text, pattern):\n",
    "    return ''.join(sorted(set(re.findall(pattern, text))))\n",
    "\n",
    "non_matching_pattern = r\"[^a-zA-Z0-9()'\\\" .,’\\-:;]\"\n",
    "train_df_with_non_matching = train_df[train_df[\"transcription\"].str.contains(pattern_with_space_dot)].copy()\n",
    "train_df_with_non_matching[\"non_matching_chars\"] = train_df_with_non_matching[\"transcription\"].apply(lambda x: find_non_matching(x, non_matching_pattern))\n",
    "train_df_with_non_matching[[\"transcription\", \"voice_creator_id\", \"non_matching_chars\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten all non-matching characters into a single list\n",
    "all_non_matching_chars = []\n",
    "for chars in train_df_with_non_matching[\"non_matching_chars\"]:\n",
    "    all_non_matching_chars.extend(list(chars))\n",
    "\n",
    "# Count occurrences of each character\n",
    "char_counts = Counter(all_non_matching_chars)\n",
    "\n",
    "# Convert to a sorted list of (character, count) tuples\n",
    "char_count_list = sorted(char_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "char_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\n",
    "    # (train_df['voice_creator_id'] == 'jV2p8qc1jLc1RFoTR8InbTJka782') &\n",
    "    (train_df['transcription'].str.contains(r'eyitiyemu'))\n",
    "]['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df[\n",
    "    # (train_df['voice_creator_id'] == 'jV2p8qc1jLc1RFoTR8InbTJka782') &\n",
    "    (train_df['transcription'].str.contains(r'\\xa0'))\n",
    "]['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a63050",
   "metadata": {},
   "outputs": [],
   "source": [
    "!# Ensure you have cloned the NeMo repository: git clone https://github.com/NVIDIA/NeMo.git\n",
    "# NEMO_GIT_FOLDER should be the path to the cloned repository.\n",
    "\n",
    "!python /ocean/projects/cis250085p/shared/KASR/nemo/scripts/process_asr_text_tokenizer.py \\\n",
    "       --manifest=\"/A_track/train_processed.json\" \\\n",
    "       --data_root=\"./kinyarwanda_tokenizers\" \\\n",
    "       --vocab_size=1024 \\\n",
    "       --tokenizer=\"spe\" \\\n",
    "       --spe_type=\"bpe\" \\\n",
    "        --spe_remove_extra_whitespaces \\\n",
    "       --log\n",
    "    #    --no_lower_case=False \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3731d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"NUMBA_NUM_THREADS\"] = \"1\"\n",
    "    torch.set_num_threads(1)\n",
    "    torch.set_num_interop_threads(1)\n",
    "\n",
    "\n",
    "config = {\n",
    "    'model_config_path': 'examples/asr/conf/conformer/conformer_ctc_bpe.yaml', # Path inside NeMo repo\n",
    "    'model': {\n",
    "        'init_from_pretrained_model': 'nvidia/parakeet-ctc-1.1b',\n",
    "        'tokenizer_dir': './kinyarwanda_tokenizers/tokenizer_spe_bpe_v1024',\n",
    "        'train_ds': {\n",
    "            'manifest_filepath': '/shared/A_track/train_processed.json',\n",
    "            'batch_size': 8,\n",
    "             'max_duration': 30.0 # Increased max duration ..>\n",
    "        },\n",
    "        'validation_ds': {\n",
    "            'manifest_filepath': '/shared/A_track/val_processed.json',\n",
    "            'batch_size': 16,\n",
    "            'max_duration': 30.0 # Increased max duration ..>\n",
    "        },\n",
    "        'optim': {\n",
    "            'name': 'adamw',\n",
    "            'lr': 0.0001,\n",
    "            'betas': [0.9, 0.98],\n",
    "            'weight_decay': 0.001,\n",
    "            'sched': {\n",
    "                'name': 'CosineAnnealing',\n",
    "                'warmup_steps': 2000\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'trainer': {\n",
    "        'accelerator': 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        'devices': 1, # Use all available GPUs\n",
    "        'max_epochs': 50,\n",
    "        'precision': 'bf16'\n",
    "    },\n",
    "    # 'exp_manager': {\n",
    "    #     \"create_checkpoint_callback\": False,\n",
    "    #     'create_wandb_logger': True,\n",
    "    #     'checkpoint_callback_params': {\n",
    "    #         'monitor': 'val_loss',\n",
    "    #         'save_top_k': 5,\n",
    "    #         'mode': 'min',\n",
    "    #         'filename': '{epoch:02d}-{val_loss:.2f}'\n",
    "    #     },\n",
    "    #     'exp_dir': './nemo_experiments',\n",
    "    #     'wandb_logger_kwargs': {\n",
    "    #         'name': 'parakeet-kinyarwanda-finetune-programmatic',\n",
    "    #         'project': 'nemo-asr'\n",
    "    #     }\n",
    "\n",
    "\n",
    "        'exp_manager': {\n",
    "            'exp_dir': './nemo_experiments',\n",
    "            'create_wandb_logger': True,\n",
    "            'wandb_logger_kwargs': {\n",
    "                'name': 'parakeet-kinyarwanda-two-phase-finetune',\n",
    "                'project': 'nemo-asr'\n",
    "            },\n",
    "            # --- ADD THIS SECTION ---\n",
    "            'create_checkpoint_callback': True,\n",
    "            'checkpoint_callback_params': {\n",
    "                'monitor': 'val_wer',  # The metric to monitor\n",
    "                'mode': 'min',         # 'min' for error rates, 'max' for accuracy\n",
    "                'save_top_k': 5,       # Save the top 5 models\n",
    "                'filename': '{epoch}-{step}-{val_wer:.2f}', # Name checkpoints with their WER\n",
    "                'verbose': True\n",
    "            }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatic_finetuning.py\n",
    "import os\n",
    "# import pytorch_lightning as pl\n",
    "import lightning.pytorch as pl \n",
    "from omegaconf import OmegaConf\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Launches a NeMo ASR fine-tuning job programmatically.\n",
    "\n",
    "Args:\n",
    "    config (dict): A dictionary containing all necessary configuration parameters.\n",
    "\"\"\"\n",
    "print(\"--- Starting Programmatic Fine-Tuning ---\")\n",
    "\n",
    "# --- 1. Set up PyTorch Lightning Trainer ---\n",
    "# The trainer is responsible for managing the training loop.\n",
    "trainer_config = config['trainer']\n",
    "trainer = pl.Trainer(**trainer_config, logger=False, enable_checkpointing=False)\n",
    "\n",
    "# --- 2. Set up Experiment Manager ---\n",
    "# The experiment manager handles logging, checkpointing, and experiment organization.\n",
    "exp_manager_config = config.get('exp_manager', {})\n",
    "# The `exp_manager` function requires the trainer to be passed to it.\n",
    "exp_dir = exp_manager(trainer, exp_manager_config)\n",
    "# \n",
    "\n",
    "# --- 3. Load Pretrained Model ---\n",
    "print(f\"Loading pretrained model: {config['model']['init_from_pretrained_model']}\")\n",
    "asr_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(\n",
    "    model_name=config['model']['init_from_pretrained_model'],\n",
    "    trainer=trainer,\n",
    "    \n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd2ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asr_model.cfg.resume_if_exists\n",
    "\n",
    "# asr_model.cfg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6be30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "print(OmegaConf.to_yaml(asr_model.cfg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1796c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4. Update Model Configuration ---\n",
    "# print(\"Updating model configuration for Kinyarwanda fine-tuning...\")\n",
    "# with open(config['model_config_path'], 'r') as f:\n",
    "#     model_cfg = OmegaConf.load(f)\n",
    "model_cfg = asr_model.cfg\n",
    "\n",
    "# Override tokenizer and dataset paths\n",
    "model_cfg.tokenizer.dir = config['model']['tokenizer_dir']\n",
    "model_cfg.train_ds.manifest_filepath = config['model']['train_ds']['manifest_filepath']\n",
    "model_cfg.validation_ds.manifest_filepath = config['model']['validation_ds']['manifest_filepath']\n",
    "\n",
    "\n",
    "# Set up the new tokenizer and vocabulary for the model\n",
    "asr_model.change_vocabulary(new_tokenizer_dir=model_cfg.tokenizer.dir, new_tokenizer_type='bpe')\n",
    "\n",
    "model_cfg.train_ds.batch_size = 6\n",
    "model_cfg.validation_ds.batch_size = 6\n",
    "\n",
    "model_cfg.train_ds.max_duration = 30\n",
    "# Set up the data loaders with the new configuration\n",
    "\n",
    "\n",
    "\n",
    "asr_model.setup_training_data(model_cfg.train_ds)\n",
    "asr_model.setup_validation_data(model_cfg.validation_ds)\n",
    "model_cfg.optim = OmegaConf.create(config['model']['optim'])\n",
    "# Override optimizer and scheduler parameters\n",
    "# OmegaConf.update(model_cfg.optim, config['model']['optim'], merge=True)\n",
    "asr_model.setup_optimization(optim_config=model_cfg.optim)\n",
    "\n",
    "\n",
    "# --- 5. Start Fine-Tuning ---\n",
    "print(\"Configuration complete. Starting training...\")\n",
    "# trainer.fit(asr_model)\n",
    "asr_model.train()\n",
    "trainer.fit(asr_model)\n",
    "print(\"Fine-tuning complete.\")\n",
    "\n",
    "# --- 6. Save the Final Model ---\n",
    "final_model_path = os.path.join(exp_dir, \"finetuned_kinyarwanda_model.nemo\")\n",
    "asr_model.save_to(final_model_path)\n",
    "print(f\"Final fine-tuned model saved to: {final_model_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0927793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# Run Python garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Empty PyTorch CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33613039",
   "metadata": {},
   "source": [
    "# 2 phase tranining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f48d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_config = {\n",
    "    'model_config_path': 'examples/asr/conf/conformer/conformer_ctc_bpe.yaml',\n",
    "    'model': {\n",
    "        'name': 'nvidia/parakeet-ctc-1.1b',\n",
    "        'tokenizer_dir': '<path_to_your_output>/kinyarwanda_tokenizers/tokenizer_spe_bpe_v1024',\n",
    "        'train_ds': {\n",
    "            'manifest_filepath': '/A_track/train_final.json',\n",
    "            'batch_size': 16\n",
    "        },\n",
    "        'validation_ds': {\n",
    "            'manifest_filepath': '/A_track/val_final.json',\n",
    "            'batch_size': 16\n",
    "        }\n",
    "    },\n",
    "    'phase1': {\n",
    "        'epochs': 10, # Number of epochs to train the decoder\n",
    "        'lr': 1e-3    # Higher learning rate for the new decoder\n",
    "    },\n",
    "    'phase2': {\n",
    "        'epochs': 50, # Number of epochs to fine-tune the whole model\n",
    "        'lr': 1e-5    # Lower learning rate for the full model fine-tuning\n",
    "    },\n",
    "    'trainer': {\n",
    "        'accelerator': 'gpu',\n",
    "        'devices': -1,\n",
    "        'precision': 'bf16',\n",
    "        'strategy': 'ddp'\n",
    "    },\n",
    "    'exp_manager': {\n",
    "        'exp_dir': './nemo_experiments',\n",
    "        'create_wandb_logger': True,\n",
    "        'wandb_logger_kwargs': {\n",
    "            'name': 'parakeet-kinyarwanda-two-phase-finetune',\n",
    "            'project': 'nemo-asr'\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b7867",
   "metadata": {
    "tags": [
     "import pandas"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dev_test_df = pd.read_json(\"/shared/B_track/dev_test.json\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9123f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df[\"file_path\"] = \"./processed/\" + dev_test_df[\"audio_path\"] + \".mel.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62258fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df[\"file_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dev_test_df[\"file_exists\"] = dev_test_df[\"file_path\"].apply(os.path.exists)\n",
    "dev_test_df[[\"file_path\", \"file_exists\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /ocean/projects/cis250085p/shared/A_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2704a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce538e",
   "metadata": {},
   "source": [
    "# run inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bfe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nemo.collections.asr.models import EncDecCTCModelBPE\n",
    "\n",
    "checkpoint_path = \"/nemo/nemo_experiments/default/checkpoints/epoch=3-step=53777-val_wer=0.15.ckpt\"\n",
    "asr_model = EncDecCTCModelBPE.restore_from(checkpoint_path, map_location=\"GPU\")\n",
    "audio_files = [\"/path/to/audio1.wav\", \"/path/to/audio2.wav\"]\n",
    "results = asr_model.transcribe(audio_files)\n",
    "for result in results:\n",
    "        print(result['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.models import EncDecCTCModelBPE\n",
    "import torch\n",
    "\n",
    "# Path to your .ckpt checkpoint\n",
    "ckpt_path = \"/nemo/nemo_experiments/default/2025-06-22_02-42-58/checkpoints/epoch=46-step=157967-val_wer=0.09-last.ckpt\"\n",
    "\n",
    "# Path to save the exported .nemo file\n",
    "nemo_path = \"/nemo/nemo_experiments/default/finetuned_epoch=3_model.nemo\"\n",
    "\n",
    "# Load model from .ckpt\n",
    "asr_model = EncDecCTCModelBPE.load_from_checkpoint(ckpt_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "asr_model.decoding.strategy = 'greedy_batch'\n",
    "\n",
    "# Export to .nemo file\n",
    "asr_model.save_to(nemo_path)\n",
    "\n",
    "print(f\"Model exported to {nemo_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3922c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"shared/track_a_audio_files\"\n",
    "train_json_path = \"shared/A_track/test.json\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "test_df = pd.read_json(train_json_path).T\n",
    "\n",
    "\n",
    "test_df[\"file_path\"] = \"processed/\"+ test_df[\"audio_path\"] +\".mel.pt\"\n",
    "test_df['audio'] = test_df['audio_path'].apply(lambda x: os.path.join(raw_path, x.replace(\"audio/\", \"\") +'.wav'))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13cff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['audio'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f1e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97583f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.models import EncDecCTCModelBPE\n",
    "\n",
    "\n",
    "nemo_path = \"KASR_2/nemo/nemo_experiments/default/2025-06-22_02-42-58/checkpoints/epoch=50-step=168050-val_wer=0.09-last.ckpt\"\n",
    "# Restore model from checkpoint\n",
    "asr_model = EncDecCTCModelBPE.restore_from(restore_path=nemo_path, map_location=\"cuda\", )\n",
    "\n",
    "# List of audio files to transcribe\n",
    "# audio_files = [\"/path/to/audio1.wav\", \"/path/to/audio2.wav\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, set decoding strategy for faster inference\n",
    "asr_model.decoding.strategy = 'greedy_batch'\n",
    "\n",
    "# Transcribe\n",
    "results = asr_model.transcribe(test_df['audio'].to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997718f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result.text)\n",
    "    results_list.append(result.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186abe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['transcription'] = results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107cb7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df['id'] = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd635d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[[\"id\", \"transcription\"]].to_csv(\"/shared/A_track/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317cf38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a9efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0ba09c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "759a3c93",
   "metadata": {},
   "source": [
    "# test resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c3101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nemo_path = \"shared/KASR_2/nemo/nemo_experiments/default/2025-06-22_02-42-58/checkpoints/epoch=50-step=168050-val_wer=0.09-last.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d47365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatic_finetuning.py\n",
    "import os\n",
    "import torch\n",
    "# import pytorch_lightning as pl\n",
    "import lightning.pytorch as pl \n",
    "from omegaconf import OmegaConf\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "import utils\n",
    "\n",
    "# import KASR.nemo.utils as utils\n",
    "device = utils.get_device_safe_threading()\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'model': {\n",
    "        'tokenizer_dir': '/KASR/nemo/kinyarwanda_tokenizers/tokenizer_spe_bpe_v1024',\n",
    "        'train_ds': {\n",
    "            'manifest_filepath': '/A_track/train_processed.json',\n",
    "            'batch_size': 3,\n",
    "             'max_duration': 30.0 # Increased max duration\n",
    "        },\n",
    "        'validation_ds': {\n",
    "            'manifest_filepath': '/A_track/val_processed.json',\n",
    "            'batch_size': 3,\n",
    "        },\n",
    "        'optim': {\n",
    "            'name': 'adamw',\n",
    "            'lr': 0.0001,\n",
    "            'betas': [0.9, 0.98],\n",
    "            'weight_decay': 0.001,\n",
    "            'sched': {\n",
    "                'name': 'CosineAnnealing',\n",
    "                'warmup_steps': 2000\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'trainer': {\n",
    "        'accelerator': 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        'devices': 1, \n",
    "        'max_epochs': 60,\n",
    "        'precision': 'bf16'\n",
    "    },     \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# --- 1. Set up PyTorch Lightning Trainer ---\n",
    "# The trainer is responsible for managing the training loop.\n",
    "trainer_config = config['trainer']\n",
    "trainer = pl.Trainer(**trainer_config,logger=False,  enable_checkpointing=False)\n",
    "\n",
    "# --- 2. Set up Experiment Manager ---\n",
    "# The experiment manager handles logging, checkpointing, and experiment organization.\n",
    "exp_manager_config = {\n",
    "            'exp_dir': '/shared/KASR/nemo/nemo_experiments',\n",
    "            'create_wandb_logger': True,\n",
    "            'wandb_logger_kwargs': {\n",
    "                'name': 'parakeet-kinyarwanda-two-phase-finetune',\n",
    "                'project': 'nemo-asr',\n",
    "    # 'resume': 'allow',\n",
    "    # 'id': \"2025-06-22_02-42-58\"\n",
    "\n",
    "\n",
    "                                    },\n",
    "            'create_checkpoint_callback': True,\n",
    "            'checkpoint_callback_params': {\n",
    "                'monitor': 'val_wer',  # The metric to monitor\n",
    "                'mode': 'min',         # 'min' for error rates, 'max' for accuracy\n",
    "                'save_top_k': 5,       # Save the top 5 models\n",
    "                'filename': '{epoch}-{step}-{val_wer:.2f}', # Name checkpoints with their WER\n",
    "                'verbose': True,\n",
    "                                        },\n",
    "                 'resume_if_exists': True,\n",
    "                'resume_ignore_no_checkpoint': True,\n",
    "                    }\n",
    "\n",
    "ckpt_path = None\n",
    "ckpt_path=\"/shared/KASR_2/nemo/nemo_experiments/default/2025-06-22_02-42-58/checkpoints/epoch=50-step=168050-val_wer=0.09-last.ckpt\"\n",
    "\n",
    "restore_path = \"/shared/KASR_2/nemo/nemo_experiments/default/2025-06-22_02-42-58/checkpoints/default.nemo\"\n",
    "exp_dir = exp_manager(trainer, exp_manager_config)\n",
    "\n",
    "\n",
    "\n",
    "# --- 3. Load Pretrained Model ---\n",
    "print(f\"Loading pretrained model: 'nvidia/parakeet-ctc-1.1b'\")\n",
    "asr_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(\n",
    "    model_name='nvidia/parakeet-ctc-1.1b',\n",
    "    trainer=trainer,\n",
    "    \n",
    ")\n",
    "\n",
    "asr_model = nemo_asr.models.EncDecCTCModelBPE.restore_from(restore_path=\"/shared/KASR_2/nemo/nemo_experiments/default/2025-06-22_02-42-58/checkpoints/epoch=50-step=168050-val_wer=0.09-last.ckpt\",\n",
    "                                                           trainer=trainer,)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac87d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 4. Update Model Configuration ---\n",
    "# print(\"Updating model configuration for Kinyarwanda fine-tuning...\")\n",
    "\n",
    "\n",
    "\n",
    "model_cfg = asr_model.cfg\n",
    "\n",
    "# Override tokenizer and dataset paths\n",
    "model_cfg.tokenizer.dir = config['model']['tokenizer_dir']\n",
    "\n",
    "asr_model.change_vocabulary(new_tokenizer_dir=model_cfg.tokenizer.dir, new_tokenizer_type='bpe')\n",
    "\n",
    "# Set up the data loaders with the new configuration\n",
    "for k, v in config['model']['train_ds'].items():\n",
    "    OmegaConf.update(model_cfg.train_ds, k, v)\n",
    "\n",
    "asr_model.setup_training_data(model_cfg.train_ds)\n",
    "\n",
    "for k, v in config['model']['validation_ds'].items():\n",
    "    OmegaConf.update(model_cfg.validation_ds, k, v)\n",
    "\n",
    "asr_model.setup_validation_data(model_cfg.validation_ds)\n",
    "\n",
    "\n",
    "# Override optimizer and scheduler parameters\n",
    "for k, v in config['model']['optim'].items():\n",
    "    OmegaConf.update(model_cfg.optim, k, v)\n",
    "\n",
    "\n",
    "if not ckpt_path:\n",
    "    asr_model.setup_optimization(optim_config=model_cfg.optim)\n",
    "\n",
    "# Set the model to use greedy decoding strategy during inference\n",
    "# asr_model.decoding.strategy = 'greedy_batch'\n",
    "\n",
    "\n",
    "# --- 5. Start Fine-Tuning ---\n",
    "print(\"Configuration complete. Starting training...\")\n",
    "# trainer.fit(asr_model)\n",
    "asr_model.train()\n",
    "trainer.fit(asr_model, ckpt_path=\"/shared/epoch=50-step=168050-val_wer=0.09-last.ckpt\")\n",
    "print(\"Fine-tuning complete.\")\n",
    "\n",
    "# --- 6. Save the Final Model ---\n",
    "final_model_path = os.path.join(exp_dir, \"finetuned_kinyarwanda_model.nemo\")\n",
    "asr_model.save_to(final_model_path)\n",
    "print(f\"Final fine-tuned model saved to: {final_model_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
