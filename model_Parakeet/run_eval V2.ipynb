{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098012d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install KenLM\n",
    "# # !apt install libeigen3-dev\n",
    "# !git clone https://github.com/kpu/kenlm.git\n",
    "# !cd kenlm && mkdir build && cd build && cmake .. && make -j\n",
    "# !pip3 install git+https://github.com/kpu/kenlm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/asr_language_modeling/ngram_lm/train_kenlm.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b809cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a581aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/shared/A_track/train.json').T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def standardize_quotation(train_df):\n",
    "    replacements = {\n",
    "        \"’\": \"'\",\n",
    "        \"‘\": \"'\",\n",
    "        \"“\": '\"',\n",
    "        \"”\": '\"',\n",
    "        \"\\n\": '',\n",
    "        u'\\xa0': u' ',\n",
    "        \"' \": \"'\",\n",
    "\n",
    "        '，':',',\n",
    "\n",
    "        '&': \"uye\",\n",
    "        '<': \"\",\n",
    "        '*': \"\",\n",
    "        '>': \"\",\n",
    "        '#': \"\",\n",
    "        '…': \".\",\n",
    "        '．': \".\",\n",
    "        '+': \"\",\n",
    "        '=': \"\",\n",
    "        '≠':'',\n",
    "        '[': \"(\",\n",
    "        ']': \")\",\n",
    "        '_':'-',\n",
    "\n",
    "        'é': 'e',\n",
    "        'ü': 'u',\n",
    "        'ì': 'i',\n",
    "        'ķ': 'k',\n",
    "        'è': 'e',\n",
    "\n",
    "        '(': '',\n",
    "        '`': \"'\",\n",
    "\n",
    "\n",
    "          '：': ':', '\"': '\"', '！': '!', '?': '?', 'à': 'a', '\\\\': '\\\\', ')': '', '/': '/', '@': ''\n",
    "    }\n",
    "    pattern = re.compile(\"|\".join(map(re.escape, replacements.keys())))\n",
    "    train_df[\"transcription\"] = train_df[\"transcription\"].str.replace(\n",
    "        pattern, lambda m: replacements[m.group()], regex=True\n",
    "    )\n",
    "    return train_df\n",
    "df = standardize_quotation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37926c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transcription'].to_csv('/shared/A_track/transcriptions.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 100 /shared/A_track/transcriptions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9035a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /shared/train_kenlm.py \\\n",
    "  nemo_model_file=/shared/KASR/nemo/nemo_experiments/default/checkpoints/default.nemo \\\n",
    "  train_paths=[/shared/A_track/cleaned.txt] \\\n",
    "  kenlm_bin_path=/shared/kenlm/build/bin \\\n",
    "  kenlm_model_file=/shared/kenlm_model.bin \\\n",
    "  ngram_length=4 \\\n",
    "  preserve_arpa=true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d792805",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /shared/train_kenlm.py \\\n",
    "  nemo_model_file=/shared/KASR/nemo/nemo_experiments/default/checkpoints/default.nemo \\\n",
    "  train_paths=[/shared/A_track/test.txt] \\\n",
    "  kenlm_bin_path=/shared/kenlm/build/bin \\\n",
    "  kenlm_model_file=/shared/kenlm_model_test.bin \\\n",
    "  ngram_length=4 \\\n",
    "  preserve_arpa=true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "\n",
    "model = kenlm.Model('/shared/kenlm_model.bin')\n",
    "print(model.score(\"Ahantu bacururiza amata ndetse\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4175b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "os.environ[\"NEMO_CACHE_DIR\"] = \"/shared/A_track/\"\n",
    "glob.glob(\"/shared/KASR/nemo/nemo_experiments/default/checkpoints/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /ocean/projects/cis250085p/shared/KASR/nemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# import KASR.nemo.utils as utils\n",
    "device = utils.get_device_safe_threading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "epoch = \"14\"\n",
    "checkpoint_paths = glob.glob(f\"/shared/KASR/nemo/nemo_experiments/default/checkpoints/epoch={epoch}*.ckpt\")\n",
    "checkpoint_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3922892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.models import EncDecCTCModelBPE\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_path = checkpoint_paths[-1]\n",
    "\n",
    "# Path to save the exported .nemo file\n",
    "nemo_path = f\"/shared/KASR/nemo/nemo_experiments/default/finetuned_epoch={epoch}_model.nemo\"\n",
    "\n",
    "# Load model from .ckpt\n",
    "asr_model = EncDecCTCModelBPE.load_from_checkpoint(checkpoint_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "asr_model.decoding.strategy = 'greedy_batch'\n",
    "\n",
    "# Export to .nemo file\n",
    "asr_model.save_to(nemo_path)\n",
    "\n",
    "print(f\"Model exported to {nemo_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce28ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"/shared/track_a_audio_files\"\n",
    "train_json_path = \"/shared/A_track/test.json\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "test_df = pd.read_json(train_json_path).T\n",
    "\n",
    "\n",
    "# test_df[\"file_path\"] = \"processed/\"+ test_df[\"audio_path\"] +\".mel.pt\"\n",
    "test_df['audio'] = test_df['audio_path'].apply(lambda x: os.path.join(raw_path, x.replace(\"audio/\", \"\") +'.wav'))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.models import EncDecCTCModelBPE\n",
    " \n",
    "# nemo_path = \"/shared/KASR/nemo/nemo_experiments/default/checkpoints/default.nemo\"\n",
    "\n",
    "asr_model = EncDecCTCModelBPE.restore_from(restore_path=nemo_path, map_location=device, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/asr_language_modeling/ngram_lm/install_beamsearch_decoders.sh\n",
    "# chmod +x install_beamsearch_decoders.sh\n",
    "\n",
    "# !mkdir -p $HOME/nemo_decoders\n",
    "\n",
    "# # Run the install script using your user directory (no sudo needed)\n",
    "# !bash install_beamsearch_decoders.sh $HOME/nemo_decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b65020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kenlm flashlight-text pyctcdecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97007e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd56630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/shared/KASR/nemo/boost_1_80_0/decoders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optionally, set decoding strategy for faster inference\n",
    "\n",
    "# !python /shared/train_kenlm.py \\\n",
    "#   nemo_model_file=/shared/KASR/nemo/nemo_experiments/default/checkpoints/default.nemo \\\n",
    "#   train_paths=[/shared/A_track/cleaned.txt] \\\n",
    "#   kenlm_bin_path=/shared/kenlm/build/bin \\\n",
    "#   kenlm_model_file=/shared/kenlm_model.bin \\\n",
    "#   ngram_length=4 \\\n",
    "#   preserve_arpa=true\n",
    "\n",
    "# asr_model.decoding.strategy = 'greedy_batch'\n",
    "import copy\n",
    "decoding_config = copy.deepcopy(asr_model.cfg.decoding)\n",
    "decoding_config.strategy = \"beam\"\n",
    "decoding_config.beam.beam_size = 8  # You can adjust this number\n",
    "decoding_config.beam.kenlm_model_path = '/shared/kenlm_model.bin'  # Path to your KenLM model\n",
    "decoding_config.beam.kenlm_path = '/shared/kenlm/build/bin'  # Path to the KenLM binary\n",
    "asr_model.change_decoding_strategy(decoding_config)\n",
    "\n",
    "# Transcribe\n",
    "results = asr_model.transcribe(test_df['audio'].to_list(),\n",
    "    batch_size=4, # Adjust batch size based on your GPU memory\n",
    "\n",
    ")\n",
    "\n",
    "results_list = []\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result.text)\n",
    "    results_list.append(result.text)\n",
    "\n",
    "test_df['transcription'] = results_list\n",
    "test_df['id'] = test_df.index\n",
    "test_df[[\"id\", \"transcription\"]].to_csv(f\"/shared/A_track/submission_epoch_{epoch}.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, set decoding strategy for faster inference\n",
    "# asr_model.decoding.strategy = 'greedy_batch'\n",
    "\n",
    "# Transcribe\n",
    "results = asr_model.transcribe(test_df['audio'].to_list())\n",
    "\n",
    "results_list = []\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result.text)\n",
    "    results_list.append(result.text)\n",
    "\n",
    "test_df['transcription'] = results_list\n",
    "test_df['id'] = test_df.index\n",
    "test_df[[\"id\", \"transcription\"]].to_csv(f\"/shared/A_track/submission_epoch_{epoch}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf0312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the submission file path\n",
    "submission_path = f\"/shared/A_track/submission_epoch_{epoch}.csv\"\n",
    "\n",
    "# Make sure kaggle is installed and API credentials are set up in ~/.kaggle/kaggle.json\n",
    "\n",
    "# Example: Upload to a Kaggle competition (replace 'your-competition-name' with the actual competition name)\n",
    "!kaggle competitions submit -c kinyarwanda-automatic-speech-recognition-track-a -f \"{submission_path}\" -m \"Submission for epoch {epoch} Automated from the script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tarfile\n",
    "\n",
    "# with tarfile.open(\"/shared/track_b_audio.tar.gz\", \"w:gz\") as tar:\n",
    "#     # Add audio files from track_b_audio_files\n",
    "#     for fname in test_df[\"audio\"]:\n",
    "#         tar.add(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shared-envpreproces)",
   "language": "python",
   "name": "shared-envpreproces"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
