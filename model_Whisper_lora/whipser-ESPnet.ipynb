{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/enh/decoder/stft_decoder.py:58: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/enh/loss/criterions/time_domain.py:446: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/enh/layers/tcn.py:458: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/enh/layers/tcn.py:499: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/enh/layers/bsrnn.py:290: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/enh/layers/bsrnn.py:331: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/enh/separator/tfgridnetv3_separator.py:369: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/enh/layers/uses.py:392: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/enh/layers/uses.py:421: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/enh/encoder/stft_encoder.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import espnetez as EZ\n",
    "from espnetez.config import from_yaml\n",
    "\n",
    "# --- Configuration Section ---\n",
    "\n",
    "# 1. Project and Data Paths\n",
    "# This should be the root folder of your project.\n",
    "PROJECT_ROOT = \".\" \n",
    "# The name of your JSON file with audio paths and transcripts.\n",
    "TRAIN_JSON_PATH = os.path.join(PROJECT_ROOT, \"train.json\") \n",
    "# The folder where all your .wav files are stored.\n",
    "WAV_DIR = os.path.join(PROJECT_ROOT, \"wavs\") \n",
    "\n",
    "# 2. Model and Training Hyperparameters\n",
    "# The name for your experiment. ESPnet will save logs and models in `exp/{EXP_NAME}`.\n",
    "EXP_NAME = \"whisper_finetune_experiment\"\n",
    "# Choose the Whisper model you want to fine-tune.\n",
    "# Options: \"openai/whisper-tiny\", \"openai/whisper-base\", \"openai/whisper-small\",\n",
    "# \"openai/whisper-medium\", \"openai/whisper-large-v2\", etc.\n",
    "# Smaller models are faster to train but less powerful.\n",
    "BASE_MODEL = \"openai/whisper-small\" \n",
    "# Training settings\n",
    "BATCH_SIZE = 4      # Adjust based on your GPU memory.\n",
    "MAX_EPOCHS = 10     # Number of times to iterate over the entire dataset.\n",
    "LEARNING_RATE = 1e-5 # Learning rate for the optimizer.\n",
    "VALIDATION_SPLIT = 0.1 # Use 10% of the data for validation.\n",
    "\n",
    "# --- End of Configuration Section ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for ESPnet-EZ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 90163\n",
      "Training samples: 89261\n",
      "Validation samples: 902\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def prepare_espnet_data(json_path, wav_dir, val_split=0.1):\n",
    "    \"\"\"\n",
    "    Loads data from a JSON file and formats it for ESPnet-EZ.\n",
    "    It also splits the data into training and validation sets.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): Path to the train.json file.\n",
    "        wav_dir (str): Path to the directory containing wav files.\n",
    "        val_split (float): The fraction of data to use for validation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries: (train_data, valid_data)\n",
    "               Each dictionary is in the format expected by ESPnet-EZ.\n",
    "    \"\"\"\n",
    "    print(\"Preparing data for ESPnet-EZ...\")\n",
    "    \n",
    "    # 1. Load the JSON file (as dict, then to list)\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            all_data_dict = json.load(f)\n",
    "            all_data = list(all_data_dict.values())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {json_path} was not found.\")\n",
    "        exit()\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: The file {json_path} is not a valid JSON file.\")\n",
    "        exit()\n",
    "\n",
    "    # 2. Shuffle data for a random split\n",
    "    random.shuffle(all_data)\n",
    "\n",
    "    # 3. Split data into training and validation sets\n",
    "    split_index = int(len(all_data) * (1 - val_split))\n",
    "    train_list = all_data[:split_index]\n",
    "    valid_list = all_data[split_index:]\n",
    "    \n",
    "    print(f\"Total samples: {len(all_data)}\")\n",
    "    print(f\"Training samples: {len(train_list)}\")\n",
    "    print(f\"Validation samples: {len(valid_list)}\")\n",
    "\n",
    "    # 4. Format the data into the required dictionary structure\n",
    "    def format_to_dict(data_list):\n",
    "        data_dict = {}\n",
    "        for i, item in enumerate(data_list):\n",
    "            # Use 'audio_path' and 'transcription' keys\n",
    "            audio_path = os.path.join(wav_dir, os.path.basename(item['audio_path'] + \".wav\"))\n",
    "            text = item['transcription']\n",
    "            \n",
    "            if not os.path.exists(audio_path):\n",
    "                print(f\"Warning: Audio file not found, skipping: {audio_path}\")\n",
    "                continue\n",
    "\n",
    "            # Create a unique utterance ID\n",
    "            utt_id = f\"utt_{i:05d}\"\n",
    "            data_dict[utt_id] = {\n",
    "                \"wav\": audio_path,\n",
    "                \"text\": text\n",
    "            }\n",
    "        return data_dict\n",
    "\n",
    "    train_data = format_to_dict(train_list)\n",
    "    valid_data = format_to_dict(valid_list)\n",
    "\n",
    "    return train_data, valid_data\n",
    "\n",
    "\n",
    "train_data, valid_data = prepare_espnet_data(\n",
    "    \"/ocean/projects/cis250085p/shared/A_track/train.json\",\n",
    "    \"/ocean/projects/cis250085p/shared/track_a_audio_files\",\n",
    "    val_split=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = \"1\"\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "torch.set_num_interop_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9b26ce33c5481dbb5743cf7b619f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 38 files:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/s2t/espnet_ctc_model.py:128: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utterance utt_00000:\n",
      "Original text: Icyapa kigaragaza akarere ka muhanga umuhanda urimo isiganwa ry'amagare, abantu bitegereza isiganwa ry'amagare ibiti biriho amashami amapoto, n'insinga z' amashanyarazi ikirere kiza.\n",
      "Predicted text: Icyapa kigaragaza Akarerere ka Muhanga umuhanda urimo isiganwa ry’amagare abantu bitegereza isiganwa ry’amagare ibiti iriho amashami, amafoto n’insinga z’amashanyarazi ikirere cyiza\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00001:\n",
      "Original text: Abana bato, bagomba kwitabwaho, kugira ngo ubuzima bwabo, burusheho kugenda neza, kandi nugaragaje ko afite ikibazo, yitabweho hakiri kare.\n",
      "Predicted text: Abana bato bagomba kwitabwaho kugira ngo ubuzima bwabo burushaho kugenda neza kandi ntugaragaje ko afite ikibazo yitabweho hakiri kare\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00002:\n",
      "Original text: Inzu ikorerwamo umurimo w'ubwogoshi aho dukundaga kuja mu gihe umusatsi watubayeho mwinshi kugira ngo twiyogosheshe tugire umubiri mwiza cane .\n",
      "Predicted text: Inzu ikorerwamo umurimo w’ubwogoshi aho dukundaga kuja mu gihe umusatsi watubayeho mwinshi kugira ngo twiyogosheshe tugire umubiri mwizacane\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00003:\n",
      "Original text: Ibinyabiziga biri mubwoko bw'ipikipiki bifite ibara ry'ubururu ndetse n'umutuku bahagaze mumuhanda igihe hari umumama wambaye igitenge gifite ibara ry'ubururu umweru ndetse n'icyatsi n'akitero gafite ibara ry'umweru biri mumuhanda inyuma hari itara rifite ibara ry'icyatsi ndetse n'umuhondo.  \n",
      "Predicted text: Ibinyabiziga biri mu bwoko bw’ipikiipiki bifite ibar ry’ubururu ndetse n’umutuku bahagaze umuhanda ryarima wambaye igitenye gifite ibar ry’ubururu ( umweru ndetse n’icyatsi’kitero gafite iari ry’umweru biri mu muhanda inyuma hara itara rifite ibara ry’icyatsi ndetse n’umuhotu\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00004:\n",
      "Original text: Umugabo uhagaze mu muhanda nyabagendwa wa kaburimbo uhagaze yambaye ishati yicyatsi yanditseho ijambo vuba, ahagaze kuri moto ifite icyo ihetsi cyanditseho vuba vuba inyuma ye hagaragara icyapa cy'umutuku kibuza kuhanyura.\n",
      "Predicted text: Gabo uhagaze mu muhanda New Gengo Limbo ahagaze yambaye ishati y’icyatsi yanditse ijambo vuba ahgaze kuri moto ifite ikiyetsi cyasoho vuba vuba.uma ye hagaragara icyapa cy’umutugu kibuja kuhanyura\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00005:\n",
      "Original text: Inyubako zitangirwamo serivisi z'ubuzima leta ikaba yarubatse ,inyubako kugira ngo abaturage bajye babona serivisi zitandukanye, zirimo z'ubuvuzi hafi yabo bitagoye kujya kuzishakira kure.\n",
      "Predicted text: Inyubako zitangirwemo serivisi z’ubuzima leta ikaba yarubatse inyubako kugira ngo abaturage bajye babona serivisi zitandukanye zirimo z’ubuvuzi hafi yabo bitagoye kujya kuzishakira kure\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00006:\n",
      "Original text: Ni inzu igurishirizwamo amadarubindi, hirya hari ibara ry'umutuku ku gikuta, hari umuntu uhicaye ndetse ku muryango hariho icyapa cy'abantu babiri bambaye amadarubindi.\n",
      "Predicted text: Ni inzu igurishirizwamo amadarubindi hirya hari ibara ry’umutuku ku gikuta hari umuntu uhicaye ndetse ku muryango hariho icyapa cy’abantu babiri bambaye amadarubindi\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00007:\n",
      "Original text: Utubari twinshi tugiye dutandukanye mu gihugu tugiye dufitemo ibinyobwa bitandukanye yaba ibisembuye cyangwa ibidasembuye, aho babigeza ku bakiriya babo uko babyifuza bakabaha serivisi nziza.\n",
      "Predicted text: Utubari ari twinshi tugiye dutandukanye mu gihugu tugiye dufitemo ibinyobwa bitandukanye yaba ibisebuye cyangwa abdasembuuye aho babigeza ku bakiriya babo uko babyifuza bakabaha serivisi nziza\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00008:\n",
      "Original text: Abagabo babiri barigusuhuzanya baseka, bambaye karuvati z'umukara, umwe afite telefone mu ntoki, undi afite ibitabo mu ntoki, yambaye n'amarinete, hirya yabo hari amagambo yanditse mu ibara ry'umuhondo y'icyongereza.\n",
      "Predicted text: Abagabo babiri bari gusozanya baseka bambaye karuvate z’umukara, umwe fite telefoni mu ntoki undafite ibitabo mu ntoki yambaye na Marnette.  Hiry yabo hari amagambo yanditse mu ibara ry’umuhondo y’Iicyongereza\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00009:\n",
      "Original text: Aba ni abagabo babiri ubona bahagaze ahantu hamwe, bishimye bari guseka nk'uko bigaragara mu maso ya bo, umwe afite amvelope mu ntoki ndetse na telefone, hari ibyo ari kwerekana, undi kuruhande yambaye umupira w'umuhondo.\n",
      "Predicted text: Aba abagabo babiri ubona bahagaze ahantu hamwe bishimye bari guseka nk’uko biganagara mu maso yabo umwe afite Ambmbelope mu ntoki ndetse na telefone aribyo ari kwerekana undi ruhande yambaye umupira w’umuhondo\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00010:\n",
      "Original text: Imbere yanjye ndahabona umuhanda wa kaburimbo hakaba harimo imodoka itwara imicanga n'amabuye yo mu bwoko bwa howo ifite ibara ritukura.\n",
      "Predicted text: Mbere yanjye ndahabona umuhanda wa kaburimbo hakaba harimo imodoka itwara imicanga n’amabuye yo mu bwoko bwa OH ifite ibara ritukura\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00011:\n",
      "Original text: Nziza ko buri muganga wese uri mu kazi, agomba guhabwa compiyuta kuko imufasha gushyira muri sisiteme abarwayi bityo rero ntibigone.\n",
      "Predicted text: ziza ko uru muganga wese uri mu kazi agomba guhabwa komp computer kuko mufasha gushyira muri siite abarwayi bityo rero n’ibigorane\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00012:\n",
      "Original text: Ikigero umwana agezemo icyo aricyo cyose aba agomba gupimwa ibiro ndetse n'uburebure n'umubyimba w'akaboko, bakareba ko imikurire ye iri kugenda uko bikwiye.\n",
      "Predicted text: Ikigero umwana agezemo icyo ari cyo cyose abagomba gupimwa ibiro ndetse n’uburebure n’umubyimba w’akaboko bakareba ko imikurire ye iri kugenda uko bikwiye\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00013:\n",
      "Original text: Imbuto ni bimwe mu bicuruzwa bidakunze gusangwa henshi, aho usanga ababishaka bajya kubirebera mu masoko manini amwe dukunze kwita ko ahurirwamo n'abantu benshi, aha usanga umucuruzi ufite ibi bicuruzwa abifata neza ndetse bikaba bigifite ubuziranenge.\n",
      "Predicted text: Imbuto ni bimwe mu bicuruzwa bidakunze gusanggwa henshi, aho usanga babishaka bajya kubirebera mu masoko manini, amwe dukunze kwita ko ahurirwamo n’abantu benshi, a usanga umucuruzi ufite ibi bicuruzwa abifata neza ndetse bikaba bigifite ubuziranenge\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00014:\n",
      "Original text: Amafaranga y'igihugu cya Kongo nayo ni amwe mu mafaranga afite agaciro gakomeye ku mugabane w'Afurika kubera ko nayo usanga ari amadorari, bityo bigatuma abantu benshi baharanira ko bayakoresha kugira ngo amafaranga yabo agire agaciro.\n",
      "Predicted text: Amafaranga y’igihugu cya Congo nayo namwe mu mafaranga afite agaciro gakomeye ku mugabane wa Afurika kubera ko nayo usanga ari amadorari, bityoubwo gato abantu benshi baharanira ko bayakoresha kugira ngo amafaranga yabo agira agaciro\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00015:\n",
      "Original text: Ni inzu nziza isize irangi ry'umuhondo ku rukuta, harimo abamama bane, bose bateruye abana, bigaragara ko baje kubapimisha cyangwa kureba imikurire yabo uko imeze, barishimye mu maso yabo.\n",
      "Predicted text: Ni inzu nziza isize irange ry’umuhondo ku bikuta harimo abamama bane bose bateruye abana bigaragara ko baje kubapimisha cyangwa kureba imikurire yabo ukomeze barishimye mu maso yabo\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00016:\n",
      "Original text: Ubuzima bukwiye guhagurukirwa mu buryo bwose bushoboka, hari inyubako zigezweho zo kwa muganga ziba zifite ikoranabuhanga ritandukanye ryifashishwa mu kwita ku buzima.\n",
      "\n",
      "Predicted text: Ubuzima bukwiye guhagurukirwa mu buryo bwose bushoboka hari inyubako zigezweho zo kwa muganga ziba zifite ikoranabuhanga ritandukanye ryifashishwa mu kwita ku buzima\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00017:\n",
      "Original text: Urujya n'uruza rwiganjemo abana ndetse n'umugabo mukuru wambaye umupira wumutuku n'ipantaro yumukara n'ndi wambaye umupira w'umweru, bahuriye ku iriba rinini riri hagati mu mbuga mu giturage, iruhande rw'iryo riba hateretse amajerekani, amabase, amakarayi, n'ibindi bikoresho bazanye gutwaramo amazi.\n",
      "Predicted text: Urujya n’uruza rwiganjemo abana ndetse n’umugabo mukuru wambaye umupira w’umutuku, ipande y’umukara n’undi wambaye umupira w’umweru, bahuriye kuiriba rinini riri hagati mu mbuga mu gituge. Iruhande rw’iryoo riba hateetsse amajereani, amabase, amakarayi y’ibindi bikoresho bazanye gutwaramo amazi\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00018:\n",
      "Original text: Inzu nziza iri mu ibara ry'umweru ikaba isakajwe n'amabati yenda kuba icyatsi, imbere yayo hakaba hari umwirasire ukurura izuba, iyi akaba ari inzu y'ababyeyi izwi nka materineti.\n",
      "Predicted text: Inzu nziza iri mu ibara ry’umweru ikabasakajwe n’amabati yenda kuba icyatsi imbere yayo akaba hari umwirasire ukurura izuba I akaba ari inzu y’ababyeyi izwi nka materineti\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00019:\n",
      "Original text: Imbere yanjye ndahabona ameza y'umukara ariho isahani y'umweru ipanzeho keke zikoze neza zifite imigongo ku ruhande, iruhande rw'iyo sahani hari iyindi kake nayo imwe iri kumeza, hirya y'isahani hari udufuniko tw'umweru dufunika keke tubiri.\n",
      "Predicted text: Mbere yanjye ndahabona ameza y’umukara ariho isahani y’umweru upanzeho keke zikoze neza zifite imigongo ku ruhande.  Randeande rw’iyo sahhan hari yindi keke nayo imwe iri kumeza hirya isahani hari udfuniko tw’umweru dufunika keke tubiri\n",
      "--------------------------------------------------------------------------------\n",
      "Utterance utt_00020:\n",
      "Original text: Hano haragaragara ihene z’amoko atandukanye. Ihene z’umukara, izivanze umukara n’umweru, iy'ibibago n’umweru, ibihogo n’umukara, zirimo zirarisha ubwatsi. Ziri mu kiraro kandi buri hene yose bayishingiye igiti cyitwa umutarimbasha, barangije bayizirikaho.\n",
      "Predicted text: Hano hagararaga ihene zamuka atandukanye ihene z’umukara zivanze umukara n’umweru, iibihgo n’umweru, ibiho n’umukara zirimo ziraarisha ubwatsi ziri mukirau kandi buri muhene yose bayishingiye igiti cyitwa mutari imfasha abarangije bayizirikaho\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "# import torch\n",
    "from espnet2.bin.s2t_inference_ctc import Speech2TextGreedySearch\n",
    "\n",
    "context_len_in_secs = 4   # left and right context when doing buffered inference\n",
    "batch_size = 2   # depends on the GPU memory\n",
    "s2t = Speech2TextGreedySearch.from_pretrained(\n",
    "    \"espnet/owsm_ctc_v4_1B\",\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    generate_interctc_outputs=False,\n",
    "    # lang_sym='<rwa>',\n",
    "    task_sym='<asr>',\n",
    ")\n",
    "\n",
    "\n",
    "# Process each audio file in the training data\n",
    "# for utt_id, data in valid_data.items():\n",
    "#     audio_path = data['wav']\n",
    "#     speech, rate = sf.read(audio_path)\n",
    "    \n",
    "#     text = s2t.decode_long_batched_buffered(\n",
    "#         speech,\n",
    "#         batch_size=batch_size,\n",
    "#         context_len_in_secs=context_len_in_secs,\n",
    "#     )\n",
    "#     print(f\"Utterance {utt_id}:\")\n",
    "#     print(f\"Original text: {data['text']}\")\n",
    "#     print(f\"Predicted text: {text}\")\n",
    "#     print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m predicted_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Process each audio file in the training data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m utt_id, data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvalid_data\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     11\u001b[0m     audio_path \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m     speech, rate \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mread(audio_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from jiwer import wer\n",
    "\n",
    "# Create empty lists to store results\n",
    "utterance_ids = []\n",
    "original_texts = []\n",
    "predicted_texts = []\n",
    "\n",
    "# Process each audio file in the training data\n",
    "for utt_id, data in valid_data.items():\n",
    "    audio_path = data['wav']\n",
    "    speech, rate = sf.read(audio_path)\n",
    "    \n",
    "    text = s2t.decode_long_batched_buffered(\n",
    "        speech,\n",
    "        batch_size=batch_size,\n",
    "        context_len_in_secs=context_len_in_secs,\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    utterance_ids.append(utt_id)\n",
    "    original_texts.append(data['text'])\n",
    "    predicted_texts.append(text)\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'utterance_id': utterance_ids,\n",
    "    'original_text': original_texts,\n",
    "    'predicted_text': predicted_texts\n",
    "})\n",
    "\n",
    "# Calculate WER for each utterance\n",
    "results_df['wer'] = [wer(orig, pred) for orig, pred in zip(results_df['original_text'], results_df['predicted_text'])]\n",
    "\n",
    "# Calculate average WER\n",
    "avg_wer = results_df['wer'].mean()\n",
    "\n",
    "print(f\"Average WER: {avg_wer:.4f}\")\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtext\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install loralib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'lora_state_dict' from 'espnet2.torch_utils' (/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/torch_utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# from espnet2.layers.lora import lora_state_dict, mark_only_lora_as_trainable\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mespnet2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lora_state_dict, mark_only_lora_as_trainable\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_lora_to_model\u001b[39m(model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, rank: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, alpha: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m):\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Applies LoRA adapters to the linear layers of a model in-place.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m        alpha: The LoRA scaling factor.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'lora_state_dict' from 'espnet2.torch_utils' (/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/torch_utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Configuration\n",
    "method = \"lora\"  # or \"full\"\n",
    "model_tag = \"espnet/owsm_ctc_v4_1B\"  # Using same model as inference\n",
    "epochs = 3\n",
    "batch_size = 4\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# --- 1. Load the Pre-trained Model ---\n",
    "print(f\"Loading pre-trained model: {model_tag}\")\n",
    "s2t = Speech2TextGreedySearch.from_pretrained(\n",
    "    model_tag,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    generate_interctc_outputs=False,\n",
    "    task_sym='<asr>',\n",
    ")\n",
    "\n",
    "# --- 2. Apply Fine-Tuning Method ---\n",
    "if method == \"lora\":\n",
    "    print(\"Applying LoRA adapters to the model for parameter-efficient fine-tuning...\")\n",
    "    s2t.s2t_model = apply_lora_to_model(s2t.s2t_model, rank=8, alpha=16)\n",
    "    print(\"LoRA applied. Only adapter weights will be trained.\")\n",
    "else:\n",
    "    print(\"Proceeding with FULL fine-tuning. All model weights will be updated.\")\n",
    "\n",
    "# Print trainable parameters info\n",
    "trainable_params = sum(p.numel() for p in s2t.s2t_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in s2t.s2t_model.parameters())\n",
    "print(f\"Fine-tuning Method: {method.upper()}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,} (~{trainable_params/total_params:.4%})\")\n",
    "print(f\"Total parameters:     {total_params:,}\")\n",
    "\n",
    "# --- 3. Prepare Training Data ---\n",
    "# Using valid_data from previous cell\n",
    "train_data = valid_data  # Assuming valid_data contains the training examples\n",
    "\n",
    "# --- 4. Training Loop ---\n",
    "output_dir = f\"./exp/{method}_finetune_{model_tag.replace('/', '_')}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [p for p in s2t.s2t_model.parameters() if p.requires_grad],\n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "s2t.s2t_model.train()\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for utt_id, data in train_data.items():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load audio\n",
    "        speech, rate = sf.read(data['wav'])\n",
    "        speech = torch.tensor(speech).to(s2t.device)\n",
    "        \n",
    "        # Get target text\n",
    "        target_text = data['text']\n",
    "        \n",
    "        # Forward pass\n",
    "        output = s2t.s2t_model(speech)\n",
    "        loss = output['loss']\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(train_data)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "torch.save({\n",
    "    'model_state_dict': s2t.s2t_model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, f\"{output_dir}/model.pt\")\n",
    "\n",
    "print(\"\\nFine-tuning complete!\")\n",
    "print(f\"Model saved to: {output_dir}/model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: espnet/owsm_ctc_v4_1B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdb809046344fdb80699f7a8e30f8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 38 files:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Speech2Text.__init__() got an unexpected keyword argument 's2t_train_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 1. Load the Pre-trained Model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading pre-trained model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m s2t \u001b[38;5;241m=\u001b[39m \u001b[43mSpeech2Text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Add other necessary arguments as needed\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/espnet2/bin/asr_inference.py:698\u001b[0m, in \u001b[0;36mSpeech2Text.from_pretrained\u001b[0;34m(model_tag, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m     d \u001b[38;5;241m=\u001b[39m ModelDownloader()\n\u001b[1;32m    696\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md\u001b[38;5;241m.\u001b[39mdownload_and_unpack(model_tag))\n\u001b[0;32m--> 698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSpeech2Text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Speech2Text.__init__() got an unexpected keyword argument 's2t_train_config'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import soundfile as sf\n",
    "from espnet2.bin.asr_inference import Speech2Text\n",
    "\n",
    "# Configuration\n",
    "method = \"lora\"  # or \"full\"\n",
    "model_tag = \"espnet/owsm_ctc_v4_1B\"\n",
    "epochs = 3\n",
    "batch_size = 4\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# 1. Load the Pre-trained Model\n",
    "print(f\"Loading pre-trained model: {model_tag}\")\n",
    "s2t = Speech2Text.from_pretrained(\n",
    "    model_tag,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    # Add other necessary arguments as needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe83984a978d4fa980f5409a58fe08cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 38 files:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from espnet2.bin.s2t_inference_ctc import Speech2TextGreedySearch\n",
    "\n",
    "model_tag = \"espnet/owsm_ctc_v4_1B\"\n",
    "\n",
    "s2t = Speech2TextGreedySearch.from_pretrained(\n",
    "    model_tag,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    generate_interctc_outputs=False,\n",
    "    task_sym='<asr>',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "espnet2.s2t.espnet_ctc_model.ESPnetS2TCTCModel"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s2t.s2t_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_lora_target_modules(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Scans the model and prints the names of all linear layers, which are\n",
    "    the typical targets for LoRA. This helps users identify which modules\n",
    "    the `lora_state_dict` function will adapt.\n",
    "\n",
    "    Args:\n",
    "        model: The PyTorch model to inspect.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Finding Potential LoRA Target Modules ---\")\n",
    "    print(\"These are the names of the `torch.nn.Linear` layers in the model.\")\n",
    "    print(\"The `lora_state_dict` utility will adapt these by default.\\n\")\n",
    "    \n",
    "    found_targets = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            found_targets.append(name)\n",
    "            \n",
    "    if found_targets:\n",
    "        for name in found_targets:\n",
    "            print(name)\n",
    "    else:\n",
    "        print(\"No `torch.nn.Linear` layers found in the model.\")\n",
    "    \n",
    "    print(\"\\n---------------------------------------------\\n\")\n",
    "    return found_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Finding Potential LoRA Target Modules ---\n",
      "These are the names of the `torch.nn.Linear` layers in the model.\n",
      "The `lora_state_dict` utility will adapt these by default.\n",
      "\n",
      "encoder.embed.out\n",
      "encoder.encoders.0.attn.linear_q\n",
      "encoder.encoders.0.attn.linear_k\n",
      "encoder.encoders.0.attn.linear_v\n",
      "encoder.encoders.0.attn.linear_out\n",
      "encoder.encoders.0.cgmlp.channel_proj1.0\n",
      "encoder.encoders.0.cgmlp.channel_proj2\n",
      "encoder.encoders.0.feed_forward.w_1\n",
      "encoder.encoders.0.feed_forward.w_2\n",
      "encoder.encoders.0.feed_forward_macaron.w_1\n",
      "encoder.encoders.0.feed_forward_macaron.w_2\n",
      "encoder.encoders.0.merge_proj\n",
      "encoder.encoders.1.attn.linear_q\n",
      "encoder.encoders.1.attn.linear_k\n",
      "encoder.encoders.1.attn.linear_v\n",
      "encoder.encoders.1.attn.linear_out\n",
      "encoder.encoders.1.cgmlp.channel_proj1.0\n",
      "encoder.encoders.1.cgmlp.channel_proj2\n",
      "encoder.encoders.1.feed_forward.w_1\n",
      "encoder.encoders.1.feed_forward.w_2\n",
      "encoder.encoders.1.feed_forward_macaron.w_1\n",
      "encoder.encoders.1.feed_forward_macaron.w_2\n",
      "encoder.encoders.1.merge_proj\n",
      "encoder.encoders.2.attn.linear_q\n",
      "encoder.encoders.2.attn.linear_k\n",
      "encoder.encoders.2.attn.linear_v\n",
      "encoder.encoders.2.attn.linear_out\n",
      "encoder.encoders.2.cgmlp.channel_proj1.0\n",
      "encoder.encoders.2.cgmlp.channel_proj2\n",
      "encoder.encoders.2.feed_forward.w_1\n",
      "encoder.encoders.2.feed_forward.w_2\n",
      "encoder.encoders.2.feed_forward_macaron.w_1\n",
      "encoder.encoders.2.feed_forward_macaron.w_2\n",
      "encoder.encoders.2.cross_attn.linear_q\n",
      "encoder.encoders.2.cross_attn.linear_k\n",
      "encoder.encoders.2.cross_attn.linear_v\n",
      "encoder.encoders.2.cross_attn.linear_out\n",
      "encoder.encoders.2.merge_proj\n",
      "encoder.encoders.3.attn.linear_q\n",
      "encoder.encoders.3.attn.linear_k\n",
      "encoder.encoders.3.attn.linear_v\n",
      "encoder.encoders.3.attn.linear_out\n",
      "encoder.encoders.3.cgmlp.channel_proj1.0\n",
      "encoder.encoders.3.cgmlp.channel_proj2\n",
      "encoder.encoders.3.feed_forward.w_1\n",
      "encoder.encoders.3.feed_forward.w_2\n",
      "encoder.encoders.3.feed_forward_macaron.w_1\n",
      "encoder.encoders.3.feed_forward_macaron.w_2\n",
      "encoder.encoders.3.merge_proj\n",
      "encoder.encoders.4.attn.linear_q\n",
      "encoder.encoders.4.attn.linear_k\n",
      "encoder.encoders.4.attn.linear_v\n",
      "encoder.encoders.4.attn.linear_out\n",
      "encoder.encoders.4.cgmlp.channel_proj1.0\n",
      "encoder.encoders.4.cgmlp.channel_proj2\n",
      "encoder.encoders.4.feed_forward.w_1\n",
      "encoder.encoders.4.feed_forward.w_2\n",
      "encoder.encoders.4.feed_forward_macaron.w_1\n",
      "encoder.encoders.4.feed_forward_macaron.w_2\n",
      "encoder.encoders.4.merge_proj\n",
      "encoder.encoders.5.attn.linear_q\n",
      "encoder.encoders.5.attn.linear_k\n",
      "encoder.encoders.5.attn.linear_v\n",
      "encoder.encoders.5.attn.linear_out\n",
      "encoder.encoders.5.cgmlp.channel_proj1.0\n",
      "encoder.encoders.5.cgmlp.channel_proj2\n",
      "encoder.encoders.5.feed_forward.w_1\n",
      "encoder.encoders.5.feed_forward.w_2\n",
      "encoder.encoders.5.feed_forward_macaron.w_1\n",
      "encoder.encoders.5.feed_forward_macaron.w_2\n",
      "encoder.encoders.5.cross_attn.linear_q\n",
      "encoder.encoders.5.cross_attn.linear_k\n",
      "encoder.encoders.5.cross_attn.linear_v\n",
      "encoder.encoders.5.cross_attn.linear_out\n",
      "encoder.encoders.5.merge_proj\n",
      "encoder.encoders.6.attn.linear_q\n",
      "encoder.encoders.6.attn.linear_k\n",
      "encoder.encoders.6.attn.linear_v\n",
      "encoder.encoders.6.attn.linear_out\n",
      "encoder.encoders.6.cgmlp.channel_proj1.0\n",
      "encoder.encoders.6.cgmlp.channel_proj2\n",
      "encoder.encoders.6.feed_forward.w_1\n",
      "encoder.encoders.6.feed_forward.w_2\n",
      "encoder.encoders.6.feed_forward_macaron.w_1\n",
      "encoder.encoders.6.feed_forward_macaron.w_2\n",
      "encoder.encoders.6.merge_proj\n",
      "encoder.encoders.7.attn.linear_q\n",
      "encoder.encoders.7.attn.linear_k\n",
      "encoder.encoders.7.attn.linear_v\n",
      "encoder.encoders.7.attn.linear_out\n",
      "encoder.encoders.7.cgmlp.channel_proj1.0\n",
      "encoder.encoders.7.cgmlp.channel_proj2\n",
      "encoder.encoders.7.feed_forward.w_1\n",
      "encoder.encoders.7.feed_forward.w_2\n",
      "encoder.encoders.7.feed_forward_macaron.w_1\n",
      "encoder.encoders.7.feed_forward_macaron.w_2\n",
      "encoder.encoders.7.merge_proj\n",
      "encoder.encoders.8.attn.linear_q\n",
      "encoder.encoders.8.attn.linear_k\n",
      "encoder.encoders.8.attn.linear_v\n",
      "encoder.encoders.8.attn.linear_out\n",
      "encoder.encoders.8.cgmlp.channel_proj1.0\n",
      "encoder.encoders.8.cgmlp.channel_proj2\n",
      "encoder.encoders.8.feed_forward.w_1\n",
      "encoder.encoders.8.feed_forward.w_2\n",
      "encoder.encoders.8.feed_forward_macaron.w_1\n",
      "encoder.encoders.8.feed_forward_macaron.w_2\n",
      "encoder.encoders.8.cross_attn.linear_q\n",
      "encoder.encoders.8.cross_attn.linear_k\n",
      "encoder.encoders.8.cross_attn.linear_v\n",
      "encoder.encoders.8.cross_attn.linear_out\n",
      "encoder.encoders.8.merge_proj\n",
      "encoder.encoders.9.attn.linear_q\n",
      "encoder.encoders.9.attn.linear_k\n",
      "encoder.encoders.9.attn.linear_v\n",
      "encoder.encoders.9.attn.linear_out\n",
      "encoder.encoders.9.cgmlp.channel_proj1.0\n",
      "encoder.encoders.9.cgmlp.channel_proj2\n",
      "encoder.encoders.9.feed_forward.w_1\n",
      "encoder.encoders.9.feed_forward.w_2\n",
      "encoder.encoders.9.feed_forward_macaron.w_1\n",
      "encoder.encoders.9.feed_forward_macaron.w_2\n",
      "encoder.encoders.9.merge_proj\n",
      "encoder.encoders.10.attn.linear_q\n",
      "encoder.encoders.10.attn.linear_k\n",
      "encoder.encoders.10.attn.linear_v\n",
      "encoder.encoders.10.attn.linear_out\n",
      "encoder.encoders.10.cgmlp.channel_proj1.0\n",
      "encoder.encoders.10.cgmlp.channel_proj2\n",
      "encoder.encoders.10.feed_forward.w_1\n",
      "encoder.encoders.10.feed_forward.w_2\n",
      "encoder.encoders.10.feed_forward_macaron.w_1\n",
      "encoder.encoders.10.feed_forward_macaron.w_2\n",
      "encoder.encoders.10.merge_proj\n",
      "encoder.encoders.11.attn.linear_q\n",
      "encoder.encoders.11.attn.linear_k\n",
      "encoder.encoders.11.attn.linear_v\n",
      "encoder.encoders.11.attn.linear_out\n",
      "encoder.encoders.11.cgmlp.channel_proj1.0\n",
      "encoder.encoders.11.cgmlp.channel_proj2\n",
      "encoder.encoders.11.feed_forward.w_1\n",
      "encoder.encoders.11.feed_forward.w_2\n",
      "encoder.encoders.11.feed_forward_macaron.w_1\n",
      "encoder.encoders.11.feed_forward_macaron.w_2\n",
      "encoder.encoders.11.cross_attn.linear_q\n",
      "encoder.encoders.11.cross_attn.linear_k\n",
      "encoder.encoders.11.cross_attn.linear_v\n",
      "encoder.encoders.11.cross_attn.linear_out\n",
      "encoder.encoders.11.merge_proj\n",
      "encoder.encoders.12.attn.linear_q\n",
      "encoder.encoders.12.attn.linear_k\n",
      "encoder.encoders.12.attn.linear_v\n",
      "encoder.encoders.12.attn.linear_out\n",
      "encoder.encoders.12.cgmlp.channel_proj1.0\n",
      "encoder.encoders.12.cgmlp.channel_proj2\n",
      "encoder.encoders.12.feed_forward.w_1\n",
      "encoder.encoders.12.feed_forward.w_2\n",
      "encoder.encoders.12.feed_forward_macaron.w_1\n",
      "encoder.encoders.12.feed_forward_macaron.w_2\n",
      "encoder.encoders.12.merge_proj\n",
      "encoder.encoders.13.attn.linear_q\n",
      "encoder.encoders.13.attn.linear_k\n",
      "encoder.encoders.13.attn.linear_v\n",
      "encoder.encoders.13.attn.linear_out\n",
      "encoder.encoders.13.cgmlp.channel_proj1.0\n",
      "encoder.encoders.13.cgmlp.channel_proj2\n",
      "encoder.encoders.13.feed_forward.w_1\n",
      "encoder.encoders.13.feed_forward.w_2\n",
      "encoder.encoders.13.feed_forward_macaron.w_1\n",
      "encoder.encoders.13.feed_forward_macaron.w_2\n",
      "encoder.encoders.13.merge_proj\n",
      "encoder.encoders.14.attn.linear_q\n",
      "encoder.encoders.14.attn.linear_k\n",
      "encoder.encoders.14.attn.linear_v\n",
      "encoder.encoders.14.attn.linear_out\n",
      "encoder.encoders.14.cgmlp.channel_proj1.0\n",
      "encoder.encoders.14.cgmlp.channel_proj2\n",
      "encoder.encoders.14.feed_forward.w_1\n",
      "encoder.encoders.14.feed_forward.w_2\n",
      "encoder.encoders.14.feed_forward_macaron.w_1\n",
      "encoder.encoders.14.feed_forward_macaron.w_2\n",
      "encoder.encoders.14.cross_attn.linear_q\n",
      "encoder.encoders.14.cross_attn.linear_k\n",
      "encoder.encoders.14.cross_attn.linear_v\n",
      "encoder.encoders.14.cross_attn.linear_out\n",
      "encoder.encoders.14.merge_proj\n",
      "encoder.encoders.15.attn.linear_q\n",
      "encoder.encoders.15.attn.linear_k\n",
      "encoder.encoders.15.attn.linear_v\n",
      "encoder.encoders.15.attn.linear_out\n",
      "encoder.encoders.15.cgmlp.channel_proj1.0\n",
      "encoder.encoders.15.cgmlp.channel_proj2\n",
      "encoder.encoders.15.feed_forward.w_1\n",
      "encoder.encoders.15.feed_forward.w_2\n",
      "encoder.encoders.15.feed_forward_macaron.w_1\n",
      "encoder.encoders.15.feed_forward_macaron.w_2\n",
      "encoder.encoders.15.merge_proj\n",
      "encoder.encoders.16.attn.linear_q\n",
      "encoder.encoders.16.attn.linear_k\n",
      "encoder.encoders.16.attn.linear_v\n",
      "encoder.encoders.16.attn.linear_out\n",
      "encoder.encoders.16.cgmlp.channel_proj1.0\n",
      "encoder.encoders.16.cgmlp.channel_proj2\n",
      "encoder.encoders.16.feed_forward.w_1\n",
      "encoder.encoders.16.feed_forward.w_2\n",
      "encoder.encoders.16.feed_forward_macaron.w_1\n",
      "encoder.encoders.16.feed_forward_macaron.w_2\n",
      "encoder.encoders.16.merge_proj\n",
      "encoder.encoders.17.attn.linear_q\n",
      "encoder.encoders.17.attn.linear_k\n",
      "encoder.encoders.17.attn.linear_v\n",
      "encoder.encoders.17.attn.linear_out\n",
      "encoder.encoders.17.cgmlp.channel_proj1.0\n",
      "encoder.encoders.17.cgmlp.channel_proj2\n",
      "encoder.encoders.17.feed_forward.w_1\n",
      "encoder.encoders.17.feed_forward.w_2\n",
      "encoder.encoders.17.feed_forward_macaron.w_1\n",
      "encoder.encoders.17.feed_forward_macaron.w_2\n",
      "encoder.encoders.17.cross_attn.linear_q\n",
      "encoder.encoders.17.cross_attn.linear_k\n",
      "encoder.encoders.17.cross_attn.linear_v\n",
      "encoder.encoders.17.cross_attn.linear_out\n",
      "encoder.encoders.17.merge_proj\n",
      "encoder.encoders.18.attn.linear_q\n",
      "encoder.encoders.18.attn.linear_k\n",
      "encoder.encoders.18.attn.linear_v\n",
      "encoder.encoders.18.attn.linear_out\n",
      "encoder.encoders.18.cgmlp.channel_proj1.0\n",
      "encoder.encoders.18.cgmlp.channel_proj2\n",
      "encoder.encoders.18.feed_forward.w_1\n",
      "encoder.encoders.18.feed_forward.w_2\n",
      "encoder.encoders.18.feed_forward_macaron.w_1\n",
      "encoder.encoders.18.feed_forward_macaron.w_2\n",
      "encoder.encoders.18.merge_proj\n",
      "encoder.encoders.19.attn.linear_q\n",
      "encoder.encoders.19.attn.linear_k\n",
      "encoder.encoders.19.attn.linear_v\n",
      "encoder.encoders.19.attn.linear_out\n",
      "encoder.encoders.19.cgmlp.channel_proj1.0\n",
      "encoder.encoders.19.cgmlp.channel_proj2\n",
      "encoder.encoders.19.feed_forward.w_1\n",
      "encoder.encoders.19.feed_forward.w_2\n",
      "encoder.encoders.19.feed_forward_macaron.w_1\n",
      "encoder.encoders.19.feed_forward_macaron.w_2\n",
      "encoder.encoders.19.merge_proj\n",
      "encoder.encoders.20.attn.linear_q\n",
      "encoder.encoders.20.attn.linear_k\n",
      "encoder.encoders.20.attn.linear_v\n",
      "encoder.encoders.20.attn.linear_out\n",
      "encoder.encoders.20.cgmlp.channel_proj1.0\n",
      "encoder.encoders.20.cgmlp.channel_proj2\n",
      "encoder.encoders.20.feed_forward.w_1\n",
      "encoder.encoders.20.feed_forward.w_2\n",
      "encoder.encoders.20.feed_forward_macaron.w_1\n",
      "encoder.encoders.20.feed_forward_macaron.w_2\n",
      "encoder.encoders.20.cross_attn.linear_q\n",
      "encoder.encoders.20.cross_attn.linear_k\n",
      "encoder.encoders.20.cross_attn.linear_v\n",
      "encoder.encoders.20.cross_attn.linear_out\n",
      "encoder.encoders.20.merge_proj\n",
      "encoder.encoders.21.attn.linear_q\n",
      "encoder.encoders.21.attn.linear_k\n",
      "encoder.encoders.21.attn.linear_v\n",
      "encoder.encoders.21.attn.linear_out\n",
      "encoder.encoders.21.cgmlp.channel_proj1.0\n",
      "encoder.encoders.21.cgmlp.channel_proj2\n",
      "encoder.encoders.21.feed_forward.w_1\n",
      "encoder.encoders.21.feed_forward.w_2\n",
      "encoder.encoders.21.feed_forward_macaron.w_1\n",
      "encoder.encoders.21.feed_forward_macaron.w_2\n",
      "encoder.encoders.21.merge_proj\n",
      "encoder.encoders.22.attn.linear_q\n",
      "encoder.encoders.22.attn.linear_k\n",
      "encoder.encoders.22.attn.linear_v\n",
      "encoder.encoders.22.attn.linear_out\n",
      "encoder.encoders.22.cgmlp.channel_proj1.0\n",
      "encoder.encoders.22.cgmlp.channel_proj2\n",
      "encoder.encoders.22.feed_forward.w_1\n",
      "encoder.encoders.22.feed_forward.w_2\n",
      "encoder.encoders.22.feed_forward_macaron.w_1\n",
      "encoder.encoders.22.feed_forward_macaron.w_2\n",
      "encoder.encoders.22.merge_proj\n",
      "encoder.encoders.23.attn.linear_q\n",
      "encoder.encoders.23.attn.linear_k\n",
      "encoder.encoders.23.attn.linear_v\n",
      "encoder.encoders.23.attn.linear_out\n",
      "encoder.encoders.23.cgmlp.channel_proj1.0\n",
      "encoder.encoders.23.cgmlp.channel_proj2\n",
      "encoder.encoders.23.feed_forward.w_1\n",
      "encoder.encoders.23.feed_forward.w_2\n",
      "encoder.encoders.23.feed_forward_macaron.w_1\n",
      "encoder.encoders.23.feed_forward_macaron.w_2\n",
      "encoder.encoders.23.cross_attn.linear_q\n",
      "encoder.encoders.23.cross_attn.linear_k\n",
      "encoder.encoders.23.cross_attn.linear_v\n",
      "encoder.encoders.23.cross_attn.linear_out\n",
      "encoder.encoders.23.merge_proj\n",
      "encoder.encoders.24.attn.linear_q\n",
      "encoder.encoders.24.attn.linear_k\n",
      "encoder.encoders.24.attn.linear_v\n",
      "encoder.encoders.24.attn.linear_out\n",
      "encoder.encoders.24.cgmlp.channel_proj1.0\n",
      "encoder.encoders.24.cgmlp.channel_proj2\n",
      "encoder.encoders.24.feed_forward.w_1\n",
      "encoder.encoders.24.feed_forward.w_2\n",
      "encoder.encoders.24.feed_forward_macaron.w_1\n",
      "encoder.encoders.24.feed_forward_macaron.w_2\n",
      "encoder.encoders.24.merge_proj\n",
      "encoder.encoders.25.attn.linear_q\n",
      "encoder.encoders.25.attn.linear_k\n",
      "encoder.encoders.25.attn.linear_v\n",
      "encoder.encoders.25.attn.linear_out\n",
      "encoder.encoders.25.cgmlp.channel_proj1.0\n",
      "encoder.encoders.25.cgmlp.channel_proj2\n",
      "encoder.encoders.25.feed_forward.w_1\n",
      "encoder.encoders.25.feed_forward.w_2\n",
      "encoder.encoders.25.feed_forward_macaron.w_1\n",
      "encoder.encoders.25.feed_forward_macaron.w_2\n",
      "encoder.encoders.25.merge_proj\n",
      "encoder.encoders.26.attn.linear_q\n",
      "encoder.encoders.26.attn.linear_k\n",
      "encoder.encoders.26.attn.linear_v\n",
      "encoder.encoders.26.attn.linear_out\n",
      "encoder.encoders.26.cgmlp.channel_proj1.0\n",
      "encoder.encoders.26.cgmlp.channel_proj2\n",
      "encoder.encoders.26.feed_forward.w_1\n",
      "encoder.encoders.26.feed_forward.w_2\n",
      "encoder.encoders.26.feed_forward_macaron.w_1\n",
      "encoder.encoders.26.feed_forward_macaron.w_2\n",
      "encoder.encoders.26.cross_attn.linear_q\n",
      "encoder.encoders.26.cross_attn.linear_k\n",
      "encoder.encoders.26.cross_attn.linear_v\n",
      "encoder.encoders.26.cross_attn.linear_out\n",
      "encoder.encoders.26.merge_proj\n",
      "encoder.conditioning_layer\n",
      "prompt_encoder.encoders.0.self_attn.linear_q\n",
      "prompt_encoder.encoders.0.self_attn.linear_k\n",
      "prompt_encoder.encoders.0.self_attn.linear_v\n",
      "prompt_encoder.encoders.0.self_attn.linear_out\n",
      "prompt_encoder.encoders.0.feed_forward.w_1\n",
      "prompt_encoder.encoders.0.feed_forward.w_2\n",
      "prompt_encoder.encoders.1.self_attn.linear_q\n",
      "prompt_encoder.encoders.1.self_attn.linear_k\n",
      "prompt_encoder.encoders.1.self_attn.linear_v\n",
      "prompt_encoder.encoders.1.self_attn.linear_out\n",
      "prompt_encoder.encoders.1.feed_forward.w_1\n",
      "prompt_encoder.encoders.1.feed_forward.w_2\n",
      "prompt_encoder.encoders.2.self_attn.linear_q\n",
      "prompt_encoder.encoders.2.self_attn.linear_k\n",
      "prompt_encoder.encoders.2.self_attn.linear_v\n",
      "prompt_encoder.encoders.2.self_attn.linear_out\n",
      "prompt_encoder.encoders.2.feed_forward.w_1\n",
      "prompt_encoder.encoders.2.feed_forward.w_2\n",
      "prompt_encoder.encoders.3.self_attn.linear_q\n",
      "prompt_encoder.encoders.3.self_attn.linear_k\n",
      "prompt_encoder.encoders.3.self_attn.linear_v\n",
      "prompt_encoder.encoders.3.self_attn.linear_out\n",
      "prompt_encoder.encoders.3.feed_forward.w_1\n",
      "prompt_encoder.encoders.3.feed_forward.w_2\n",
      "embed_proj\n",
      "prompt_proj\n",
      "ctc.ctc_lo\n",
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['encoder.embed.out',\n",
       " 'encoder.encoders.0.attn.linear_q',\n",
       " 'encoder.encoders.0.attn.linear_k',\n",
       " 'encoder.encoders.0.attn.linear_v',\n",
       " 'encoder.encoders.0.attn.linear_out',\n",
       " 'encoder.encoders.0.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.0.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.0.feed_forward.w_1',\n",
       " 'encoder.encoders.0.feed_forward.w_2',\n",
       " 'encoder.encoders.0.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.0.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.0.merge_proj',\n",
       " 'encoder.encoders.1.attn.linear_q',\n",
       " 'encoder.encoders.1.attn.linear_k',\n",
       " 'encoder.encoders.1.attn.linear_v',\n",
       " 'encoder.encoders.1.attn.linear_out',\n",
       " 'encoder.encoders.1.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.1.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.1.feed_forward.w_1',\n",
       " 'encoder.encoders.1.feed_forward.w_2',\n",
       " 'encoder.encoders.1.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.1.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.1.merge_proj',\n",
       " 'encoder.encoders.2.attn.linear_q',\n",
       " 'encoder.encoders.2.attn.linear_k',\n",
       " 'encoder.encoders.2.attn.linear_v',\n",
       " 'encoder.encoders.2.attn.linear_out',\n",
       " 'encoder.encoders.2.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.2.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.2.feed_forward.w_1',\n",
       " 'encoder.encoders.2.feed_forward.w_2',\n",
       " 'encoder.encoders.2.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.2.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.2.cross_attn.linear_q',\n",
       " 'encoder.encoders.2.cross_attn.linear_k',\n",
       " 'encoder.encoders.2.cross_attn.linear_v',\n",
       " 'encoder.encoders.2.cross_attn.linear_out',\n",
       " 'encoder.encoders.2.merge_proj',\n",
       " 'encoder.encoders.3.attn.linear_q',\n",
       " 'encoder.encoders.3.attn.linear_k',\n",
       " 'encoder.encoders.3.attn.linear_v',\n",
       " 'encoder.encoders.3.attn.linear_out',\n",
       " 'encoder.encoders.3.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.3.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.3.feed_forward.w_1',\n",
       " 'encoder.encoders.3.feed_forward.w_2',\n",
       " 'encoder.encoders.3.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.3.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.3.merge_proj',\n",
       " 'encoder.encoders.4.attn.linear_q',\n",
       " 'encoder.encoders.4.attn.linear_k',\n",
       " 'encoder.encoders.4.attn.linear_v',\n",
       " 'encoder.encoders.4.attn.linear_out',\n",
       " 'encoder.encoders.4.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.4.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.4.feed_forward.w_1',\n",
       " 'encoder.encoders.4.feed_forward.w_2',\n",
       " 'encoder.encoders.4.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.4.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.4.merge_proj',\n",
       " 'encoder.encoders.5.attn.linear_q',\n",
       " 'encoder.encoders.5.attn.linear_k',\n",
       " 'encoder.encoders.5.attn.linear_v',\n",
       " 'encoder.encoders.5.attn.linear_out',\n",
       " 'encoder.encoders.5.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.5.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.5.feed_forward.w_1',\n",
       " 'encoder.encoders.5.feed_forward.w_2',\n",
       " 'encoder.encoders.5.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.5.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.5.cross_attn.linear_q',\n",
       " 'encoder.encoders.5.cross_attn.linear_k',\n",
       " 'encoder.encoders.5.cross_attn.linear_v',\n",
       " 'encoder.encoders.5.cross_attn.linear_out',\n",
       " 'encoder.encoders.5.merge_proj',\n",
       " 'encoder.encoders.6.attn.linear_q',\n",
       " 'encoder.encoders.6.attn.linear_k',\n",
       " 'encoder.encoders.6.attn.linear_v',\n",
       " 'encoder.encoders.6.attn.linear_out',\n",
       " 'encoder.encoders.6.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.6.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.6.feed_forward.w_1',\n",
       " 'encoder.encoders.6.feed_forward.w_2',\n",
       " 'encoder.encoders.6.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.6.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.6.merge_proj',\n",
       " 'encoder.encoders.7.attn.linear_q',\n",
       " 'encoder.encoders.7.attn.linear_k',\n",
       " 'encoder.encoders.7.attn.linear_v',\n",
       " 'encoder.encoders.7.attn.linear_out',\n",
       " 'encoder.encoders.7.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.7.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.7.feed_forward.w_1',\n",
       " 'encoder.encoders.7.feed_forward.w_2',\n",
       " 'encoder.encoders.7.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.7.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.7.merge_proj',\n",
       " 'encoder.encoders.8.attn.linear_q',\n",
       " 'encoder.encoders.8.attn.linear_k',\n",
       " 'encoder.encoders.8.attn.linear_v',\n",
       " 'encoder.encoders.8.attn.linear_out',\n",
       " 'encoder.encoders.8.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.8.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.8.feed_forward.w_1',\n",
       " 'encoder.encoders.8.feed_forward.w_2',\n",
       " 'encoder.encoders.8.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.8.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.8.cross_attn.linear_q',\n",
       " 'encoder.encoders.8.cross_attn.linear_k',\n",
       " 'encoder.encoders.8.cross_attn.linear_v',\n",
       " 'encoder.encoders.8.cross_attn.linear_out',\n",
       " 'encoder.encoders.8.merge_proj',\n",
       " 'encoder.encoders.9.attn.linear_q',\n",
       " 'encoder.encoders.9.attn.linear_k',\n",
       " 'encoder.encoders.9.attn.linear_v',\n",
       " 'encoder.encoders.9.attn.linear_out',\n",
       " 'encoder.encoders.9.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.9.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.9.feed_forward.w_1',\n",
       " 'encoder.encoders.9.feed_forward.w_2',\n",
       " 'encoder.encoders.9.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.9.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.9.merge_proj',\n",
       " 'encoder.encoders.10.attn.linear_q',\n",
       " 'encoder.encoders.10.attn.linear_k',\n",
       " 'encoder.encoders.10.attn.linear_v',\n",
       " 'encoder.encoders.10.attn.linear_out',\n",
       " 'encoder.encoders.10.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.10.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.10.feed_forward.w_1',\n",
       " 'encoder.encoders.10.feed_forward.w_2',\n",
       " 'encoder.encoders.10.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.10.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.10.merge_proj',\n",
       " 'encoder.encoders.11.attn.linear_q',\n",
       " 'encoder.encoders.11.attn.linear_k',\n",
       " 'encoder.encoders.11.attn.linear_v',\n",
       " 'encoder.encoders.11.attn.linear_out',\n",
       " 'encoder.encoders.11.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.11.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.11.feed_forward.w_1',\n",
       " 'encoder.encoders.11.feed_forward.w_2',\n",
       " 'encoder.encoders.11.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.11.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.11.cross_attn.linear_q',\n",
       " 'encoder.encoders.11.cross_attn.linear_k',\n",
       " 'encoder.encoders.11.cross_attn.linear_v',\n",
       " 'encoder.encoders.11.cross_attn.linear_out',\n",
       " 'encoder.encoders.11.merge_proj',\n",
       " 'encoder.encoders.12.attn.linear_q',\n",
       " 'encoder.encoders.12.attn.linear_k',\n",
       " 'encoder.encoders.12.attn.linear_v',\n",
       " 'encoder.encoders.12.attn.linear_out',\n",
       " 'encoder.encoders.12.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.12.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.12.feed_forward.w_1',\n",
       " 'encoder.encoders.12.feed_forward.w_2',\n",
       " 'encoder.encoders.12.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.12.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.12.merge_proj',\n",
       " 'encoder.encoders.13.attn.linear_q',\n",
       " 'encoder.encoders.13.attn.linear_k',\n",
       " 'encoder.encoders.13.attn.linear_v',\n",
       " 'encoder.encoders.13.attn.linear_out',\n",
       " 'encoder.encoders.13.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.13.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.13.feed_forward.w_1',\n",
       " 'encoder.encoders.13.feed_forward.w_2',\n",
       " 'encoder.encoders.13.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.13.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.13.merge_proj',\n",
       " 'encoder.encoders.14.attn.linear_q',\n",
       " 'encoder.encoders.14.attn.linear_k',\n",
       " 'encoder.encoders.14.attn.linear_v',\n",
       " 'encoder.encoders.14.attn.linear_out',\n",
       " 'encoder.encoders.14.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.14.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.14.feed_forward.w_1',\n",
       " 'encoder.encoders.14.feed_forward.w_2',\n",
       " 'encoder.encoders.14.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.14.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.14.cross_attn.linear_q',\n",
       " 'encoder.encoders.14.cross_attn.linear_k',\n",
       " 'encoder.encoders.14.cross_attn.linear_v',\n",
       " 'encoder.encoders.14.cross_attn.linear_out',\n",
       " 'encoder.encoders.14.merge_proj',\n",
       " 'encoder.encoders.15.attn.linear_q',\n",
       " 'encoder.encoders.15.attn.linear_k',\n",
       " 'encoder.encoders.15.attn.linear_v',\n",
       " 'encoder.encoders.15.attn.linear_out',\n",
       " 'encoder.encoders.15.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.15.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.15.feed_forward.w_1',\n",
       " 'encoder.encoders.15.feed_forward.w_2',\n",
       " 'encoder.encoders.15.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.15.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.15.merge_proj',\n",
       " 'encoder.encoders.16.attn.linear_q',\n",
       " 'encoder.encoders.16.attn.linear_k',\n",
       " 'encoder.encoders.16.attn.linear_v',\n",
       " 'encoder.encoders.16.attn.linear_out',\n",
       " 'encoder.encoders.16.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.16.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.16.feed_forward.w_1',\n",
       " 'encoder.encoders.16.feed_forward.w_2',\n",
       " 'encoder.encoders.16.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.16.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.16.merge_proj',\n",
       " 'encoder.encoders.17.attn.linear_q',\n",
       " 'encoder.encoders.17.attn.linear_k',\n",
       " 'encoder.encoders.17.attn.linear_v',\n",
       " 'encoder.encoders.17.attn.linear_out',\n",
       " 'encoder.encoders.17.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.17.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.17.feed_forward.w_1',\n",
       " 'encoder.encoders.17.feed_forward.w_2',\n",
       " 'encoder.encoders.17.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.17.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.17.cross_attn.linear_q',\n",
       " 'encoder.encoders.17.cross_attn.linear_k',\n",
       " 'encoder.encoders.17.cross_attn.linear_v',\n",
       " 'encoder.encoders.17.cross_attn.linear_out',\n",
       " 'encoder.encoders.17.merge_proj',\n",
       " 'encoder.encoders.18.attn.linear_q',\n",
       " 'encoder.encoders.18.attn.linear_k',\n",
       " 'encoder.encoders.18.attn.linear_v',\n",
       " 'encoder.encoders.18.attn.linear_out',\n",
       " 'encoder.encoders.18.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.18.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.18.feed_forward.w_1',\n",
       " 'encoder.encoders.18.feed_forward.w_2',\n",
       " 'encoder.encoders.18.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.18.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.18.merge_proj',\n",
       " 'encoder.encoders.19.attn.linear_q',\n",
       " 'encoder.encoders.19.attn.linear_k',\n",
       " 'encoder.encoders.19.attn.linear_v',\n",
       " 'encoder.encoders.19.attn.linear_out',\n",
       " 'encoder.encoders.19.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.19.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.19.feed_forward.w_1',\n",
       " 'encoder.encoders.19.feed_forward.w_2',\n",
       " 'encoder.encoders.19.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.19.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.19.merge_proj',\n",
       " 'encoder.encoders.20.attn.linear_q',\n",
       " 'encoder.encoders.20.attn.linear_k',\n",
       " 'encoder.encoders.20.attn.linear_v',\n",
       " 'encoder.encoders.20.attn.linear_out',\n",
       " 'encoder.encoders.20.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.20.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.20.feed_forward.w_1',\n",
       " 'encoder.encoders.20.feed_forward.w_2',\n",
       " 'encoder.encoders.20.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.20.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.20.cross_attn.linear_q',\n",
       " 'encoder.encoders.20.cross_attn.linear_k',\n",
       " 'encoder.encoders.20.cross_attn.linear_v',\n",
       " 'encoder.encoders.20.cross_attn.linear_out',\n",
       " 'encoder.encoders.20.merge_proj',\n",
       " 'encoder.encoders.21.attn.linear_q',\n",
       " 'encoder.encoders.21.attn.linear_k',\n",
       " 'encoder.encoders.21.attn.linear_v',\n",
       " 'encoder.encoders.21.attn.linear_out',\n",
       " 'encoder.encoders.21.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.21.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.21.feed_forward.w_1',\n",
       " 'encoder.encoders.21.feed_forward.w_2',\n",
       " 'encoder.encoders.21.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.21.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.21.merge_proj',\n",
       " 'encoder.encoders.22.attn.linear_q',\n",
       " 'encoder.encoders.22.attn.linear_k',\n",
       " 'encoder.encoders.22.attn.linear_v',\n",
       " 'encoder.encoders.22.attn.linear_out',\n",
       " 'encoder.encoders.22.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.22.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.22.feed_forward.w_1',\n",
       " 'encoder.encoders.22.feed_forward.w_2',\n",
       " 'encoder.encoders.22.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.22.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.22.merge_proj',\n",
       " 'encoder.encoders.23.attn.linear_q',\n",
       " 'encoder.encoders.23.attn.linear_k',\n",
       " 'encoder.encoders.23.attn.linear_v',\n",
       " 'encoder.encoders.23.attn.linear_out',\n",
       " 'encoder.encoders.23.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.23.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.23.feed_forward.w_1',\n",
       " 'encoder.encoders.23.feed_forward.w_2',\n",
       " 'encoder.encoders.23.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.23.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.23.cross_attn.linear_q',\n",
       " 'encoder.encoders.23.cross_attn.linear_k',\n",
       " 'encoder.encoders.23.cross_attn.linear_v',\n",
       " 'encoder.encoders.23.cross_attn.linear_out',\n",
       " 'encoder.encoders.23.merge_proj',\n",
       " 'encoder.encoders.24.attn.linear_q',\n",
       " 'encoder.encoders.24.attn.linear_k',\n",
       " 'encoder.encoders.24.attn.linear_v',\n",
       " 'encoder.encoders.24.attn.linear_out',\n",
       " 'encoder.encoders.24.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.24.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.24.feed_forward.w_1',\n",
       " 'encoder.encoders.24.feed_forward.w_2',\n",
       " 'encoder.encoders.24.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.24.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.24.merge_proj',\n",
       " 'encoder.encoders.25.attn.linear_q',\n",
       " 'encoder.encoders.25.attn.linear_k',\n",
       " 'encoder.encoders.25.attn.linear_v',\n",
       " 'encoder.encoders.25.attn.linear_out',\n",
       " 'encoder.encoders.25.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.25.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.25.feed_forward.w_1',\n",
       " 'encoder.encoders.25.feed_forward.w_2',\n",
       " 'encoder.encoders.25.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.25.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.25.merge_proj',\n",
       " 'encoder.encoders.26.attn.linear_q',\n",
       " 'encoder.encoders.26.attn.linear_k',\n",
       " 'encoder.encoders.26.attn.linear_v',\n",
       " 'encoder.encoders.26.attn.linear_out',\n",
       " 'encoder.encoders.26.cgmlp.channel_proj1.0',\n",
       " 'encoder.encoders.26.cgmlp.channel_proj2',\n",
       " 'encoder.encoders.26.feed_forward.w_1',\n",
       " 'encoder.encoders.26.feed_forward.w_2',\n",
       " 'encoder.encoders.26.feed_forward_macaron.w_1',\n",
       " 'encoder.encoders.26.feed_forward_macaron.w_2',\n",
       " 'encoder.encoders.26.cross_attn.linear_q',\n",
       " 'encoder.encoders.26.cross_attn.linear_k',\n",
       " 'encoder.encoders.26.cross_attn.linear_v',\n",
       " 'encoder.encoders.26.cross_attn.linear_out',\n",
       " 'encoder.encoders.26.merge_proj',\n",
       " 'encoder.conditioning_layer',\n",
       " 'prompt_encoder.encoders.0.self_attn.linear_q',\n",
       " 'prompt_encoder.encoders.0.self_attn.linear_k',\n",
       " 'prompt_encoder.encoders.0.self_attn.linear_v',\n",
       " 'prompt_encoder.encoders.0.self_attn.linear_out',\n",
       " 'prompt_encoder.encoders.0.feed_forward.w_1',\n",
       " 'prompt_encoder.encoders.0.feed_forward.w_2',\n",
       " 'prompt_encoder.encoders.1.self_attn.linear_q',\n",
       " 'prompt_encoder.encoders.1.self_attn.linear_k',\n",
       " 'prompt_encoder.encoders.1.self_attn.linear_v',\n",
       " 'prompt_encoder.encoders.1.self_attn.linear_out',\n",
       " 'prompt_encoder.encoders.1.feed_forward.w_1',\n",
       " 'prompt_encoder.encoders.1.feed_forward.w_2',\n",
       " 'prompt_encoder.encoders.2.self_attn.linear_q',\n",
       " 'prompt_encoder.encoders.2.self_attn.linear_k',\n",
       " 'prompt_encoder.encoders.2.self_attn.linear_v',\n",
       " 'prompt_encoder.encoders.2.self_attn.linear_out',\n",
       " 'prompt_encoder.encoders.2.feed_forward.w_1',\n",
       " 'prompt_encoder.encoders.2.feed_forward.w_2',\n",
       " 'prompt_encoder.encoders.3.self_attn.linear_q',\n",
       " 'prompt_encoder.encoders.3.self_attn.linear_k',\n",
       " 'prompt_encoder.encoders.3.self_attn.linear_v',\n",
       " 'prompt_encoder.encoders.3.self_attn.linear_out',\n",
       " 'prompt_encoder.encoders.3.feed_forward.w_1',\n",
       " 'prompt_encoder.encoders.3.feed_forward.w_2',\n",
       " 'embed_proj',\n",
       " 'prompt_proj',\n",
       " 'ctc.ctc_lo']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_lora_target_modules(s2t.s2t_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_target_modules = [\n",
    "            \"*.attn.linear_q\",\n",
    "            \"*.attn.linear_v\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ESPnetS2TCTCModel' object has no attribute 'enable_lora'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ms2t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms2t_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_lora\u001b[49m(rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m/ocean/projects/cis250085p/shared/espnet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1930\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ESPnetS2TCTCModel' object has no attribute 'enable_lora'"
     ]
    }
   ],
   "source": [
    "s2t.s2t_model.enable_lora(rank=8, alpha=16)\n",
    "\n",
    "\n",
    "create_lora_adapter(\n",
    "    model: torch.nn.Module,\n",
    "    rank: int = 8,\n",
    "    alpha: int = 8,\n",
    "    dropout_rate: float = 0.0,\n",
    "    target_modules: List[str] = [\"query\"],\n",
    "    bias_type: Optional[str] = \"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling LoRA adapters for parameter-efficient fine-tuning...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Speech2TextGreedySearch' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnabling LoRA adapters for parameter-efficient fine-tuning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LoRA is now enabled via config or CLI, not by manual injection.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# If using CLI: add --use_lora true --lora_rank 8 --lora_alpha 16\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# If using code, check if your ESPnet2 exposes a method like enable_lora()\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43ms2t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_lora\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      8\u001b[0m     s2t\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39menable_lora(rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Speech2TextGreedySearch' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Apply Fine-Tuning Method\n",
    "if method == \"lora\":\n",
    "    print(\"Enabling LoRA adapters for parameter-efficient fine-tuning...\")\n",
    "    # LoRA is now enabled via config or CLI, not by manual injection.\n",
    "    # If using CLI: add --use_lora true --lora_rank 8 --lora_alpha 16\n",
    "    # If using code, check if your ESPnet2 exposes a method like enable_lora()\n",
    "    if hasattr(s2t.model, \"enable_lora\"):\n",
    "        s2t.model.enable_lora(rank=8, alpha=16)\n",
    "    else:\n",
    "        raise NotImplementedError(\"LoRA must be enabled via config or CLI in this ESPnet2 version.\")\n",
    "    print(\"LoRA enabled. Only adapter weights will be trained.\")\n",
    "else:\n",
    "    print(\"Proceeding with FULL fine-tuning. All model weights will be updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Method: LORA\n",
      "Trainable parameters: 1,011,342,162 (~100.0000%)\n",
      "Total parameters:     1,011,342,162\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print trainable parameters info\n",
    "trainable_params = sum(p.numel() for p in s2t.s2t_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in s2t.s2t_model.parameters())\n",
    "print(f\"Fine-tuning Method: {method.upper()}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,} (~{trainable_params/total_params:.4%})\")\n",
    "print(f\"Total parameters:     {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Prepare Training Data\n",
    "# You must provide 'train_data' as a dict: {utt_id: {'wav': path, 'text': str}}\n",
    "# Example: train_data = {'utt1': {'wav': 'audio1.wav', 'text': 'hello world'}, ...}\n",
    "\n",
    "# 4. Training Loop\n",
    "output_dir = f\"./exp/{method}_finetune_{model_tag.replace('/', '_')}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [p for p in s2t.model.parameters() if p.requires_grad],\n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "s2t.model.train()\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for utt_id, data in train_data.items():\n",
    "        optimizer.zero_grad()\n",
    "        speech, rate = sf.read(data['wav'])\n",
    "        speech = torch.tensor(speech).to(s2t.device)\n",
    "        target_text = data['text']\n",
    "        # Forward pass (update as per your model's API)\n",
    "        output = s2t.model(speech)\n",
    "        loss = output['loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_data)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "torch.save({\n",
    "    'model_state_dict': s2t.model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, f\"{output_dir}/model.pt\")\n",
    "\n",
    "print(\"\\nFine-tuning complete!\")\n",
    "print(f\"Model saved to: {output_dir}/model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
